[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Info",
    "section": "",
    "text": "Education\nNova Acrópole | Florianópolis, SC, Brasil\nFilosofia na tradição Clássica | 2014-2015\nUniversidade Uniderp | Campo Grande, MS, Brasil\nMestrado Produção e Gestão Agroindustrial | 2008-2010"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Carvalho Ribeiro Blog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nExploração\n\n\n\n\n\n\n\n\n\n\n\nAug 7, 2022\n\n\nMarcelo Carvalho dos Anjos\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nModelos\n\n\n\n\n\n\n\n\n\n\n\nAug 6, 2022\n\n\nMarcelo Carvalho dos Anjos\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nModelos\n\n\n\n\n\n\n\n\n\n\n\nAug 3, 2022\n\n\nMarcelo Carvalho dos Anjos\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nDemanda\n\n\nDados\n\n\nFerramentas\n\n\nExploração\n\n\nModelos\n\n\nVersionamento\n\n\nComunicação\n\n\nAplicação\n\n\n\n\n\n\n\n\n\n\n\nAug 3, 2022\n\n\nMarcelo Carvalho dos Anjos\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Avaliar resultados de modelo preditivo com matriz de confusão",
    "section": "",
    "text": "Qual o objetivo\n\nPor ser visual ajuda a responder rapidamente será que meu modelo teve um bom desempenho, onde deu errado, como posso corrigir ?\nAs diversas saídas de previõe permite a criação de indicadores que serão uteis nos ajustes mais adequados conforme a necessidade do trabalho que está sendo desenvolvido.\n\n\n\nDe onde vem a demanda\n\nEm 1904 Karl Pearson criou a tabela de contingência. Por que precisamos e uma matriz de confusao se tevem a acuracidade ?\nImagine prever quantas pessoas estao infectadas com um virus contagioso antes de apresentar sintomas e isola-las da populacao saudavel.\n\n\n\nComo fazer\nPara reproduzir os códigos abaixo serão necessários os pacotes tidyverse , tidymodels e janitor\nO principal pacote que será usando para analisar uma matriz de confusão é o pacote yardstick que já é carregado quando chamamos o pacote tidymodels.\n\n#packages\nlibrary(tidyverse)\nlibrary(tidymodels)\n\n#check\ntwo_class_example %>% filter(Class1 >0.5) %>% janitor::tabyl(truth)\n\n  truth   n   percent\n Class1 227 0.8194946\n Class2  50 0.1805054\n\n#exemplo de tabela cruzada usando janitor\ntwo_class_example %>% \n  janitor::tabyl(truth, predicted) %>% \n  janitor::adorn_totals(where = c(\"col\", \"row\")) %>% \n  janitor::adorn_title()\n\n        predicted             \n  truth    Class1 Class2 Total\n Class1       227     31   258\n Class2        50    192   242\n  Total       277    223   500\n\n#trocando nomes\ntwo_class_example %>% \n  conf_mat(truth =truth, estimate =predicted, dnn =c(\"vlr_previsto\",\"vlr_real\"))\n\n            vlr_real\nvlr_previsto Class1 Class2\n      Class1    227     50\n      Class2     31    192\n\n#plot heatmap\ntwo_class_example %>% \n  conf_mat(truth = truth, estimate = predicted) %>% \n  autoplot(type = \"heatmap\")\n\n\n\n#acuracia- prop de acertos do modelo total de acerto / total previu\ntwo_class_example %>% \n  accuracy(truth= truth, estimate = predicted)\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.838\n\n#sensibilidade ou recall é a proporção de casos positivos classif corretamente\n#Raio X de aeroporto prioriza sensitivity\n#diagnóstico de cancer também pois o não diagnóstico resulta em atraso no tratamento\ntwo_class_example %>% \n  yardstick::sens(truth= truth, estimate = predicted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 sens    binary         0.880\n\n#Recall métrica útil nos casos em que o Falso Negativo supera o falso positivol\n#importante em casos médicos em que não importa se disparamos um alarme \n#falso, mas os casos positivos reais não devem passar despercebidos!\n#Em nosso exemplo, Recall seria uma métrica melhor porque não queremos dar alta \n#acidentalmente a uma pessoa infectada e deixá-la se misturar com a população \n#saudável,espalhando o vírus contagioso. \n#Agora você pode entender por que a acuracidade foi uma métrica ruim para modelo.\ntwo_class_example %>% \n  yardstick::recall(truth= truth, estimate = predicted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 recall  binary         0.880\n\n#kappa\ntwo_class_example %>% \n  yardstick::kap(truth= truth, estimate = predicted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 kap     binary         0.675\n\n#npv\ntwo_class_example %>% \n  yardstick::npv(truth= truth, estimate = predicted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 npv     binary         0.861\n\n#ppv\ntwo_class_example %>% \n  yardstick::ppv(truth= truth, estimate = predicted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 ppv     binary         0.819\n\n#A precisão é util nos casos em que os falsos positivos são uma preocupação \n#maior do que os falsos negativos.\n#A precisão é importante em sistemas de recomendação de música ou vídeo, \n#sites de comércio eletrônico, etc. Resultados errados podem levar à perda de \n#clientes e prejudicar o negócio.\ntwo_class_example %>% \n  yardstick::precision(truth= truth, estimate = predicted)\n\n# A tibble: 1 × 3\n  .metric   .estimator .estimate\n  <chr>     <chr>          <dbl>\n1 precision binary         0.819\n\n#spec\ntwo_class_example %>% \n  yardstick::spec(truth= truth, estimate = predicted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 spec    binary         0.793\n\n#roc_curve\ntwo_class_example %>% \n  roc_curve(truth = truth, estimate = Class1 ) %>% autoplot()\n\n\n\n#roc_auc\ntwo_class_example %>% \n  roc_auc(truth = truth, estimate = Class1 )\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.939\n\n\n\n\n\n\n\n\nDiferença entre incidência e prevalencia\n\n\n\n\n\nIncidencia é o número de casos recém-diagnosticados de uma doença. Número de novos casos de uma doença dividido pelo número de pessoas em risco para a doença. Se, ao longo de um ano, cinco mulheres são diagnosticadas com câncer de mama, de uma população total de 200 mulheres do estudo (que não têm câncer de mama no início do período de estudo), então diríamos que a incidência de câncer de mama câncer nesta população foi de 0,025. (ou 2.500 por 100.000 mulheres-anos de estudo)\nPrevalência é o número total de casos da doença existentes em uma população. A taxa de prevalência é o número total de casos de uma doença existente em uma população dividido pela população total. Assim, se uma medida de câncer é feita em uma população de 40.000 pessoas e 1.200 foram recentemente diagnosticadas com câncer e 3.500 estão vivendo com câncer, então a prevalência de câncer é de 0,118. (ou 11.750 por 100.000 pessoas)\n\n\n\n\n\nPra onde vai quem é o cliente\n\nA próxima etapa é o ajuste, finalização e comunicação do modelo.\n\n\n\nQual o resultado\n\nAperfeiçoar as técnicas de avaliação de performance de modelos poupando tempo e dinheiro.\nFacilitar o processo de busca por melhorias nos modelos de previsão.\nMelhorar a comunicação dos resultados."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Motivação para o blog",
    "section": "",
    "text": "Como serão divididos os tópicos ?\n\nDemanda, definição do problema, objetivos e métricas de sucesso - Contém a origem e tipos de necessidade que é o que torna todo o restante do trabalho necessário.\nDados - Contém conceitos com o objetivo de estimular a observação, abstração e entendimento sobre o que são dados.\nFerramentas - Contém ferramentas como R(RStudio), Oracle SQL*plus, Oracle SNO, SPSS, Sphinx, Qlikview, PowerBI e excel.\nExploração - Contém visualização de dados, análise exploratória, tabelas, queries, planilhas de excel, folhas de verificação etc.\nModelos - Contém alguns tipos de modelos descritivos, preditivos, inferenciais, otimização entre outros.\nVersionamento e Reprodutibilidade - Contém processos para desenvolvimento de documentos reproduzíveis usando versionamento github, git, criação de documentos quarto_pub e rmardown, criação de livros bookdown entre outros.\nComunicação - Contém abordagens sobre comunicação das estatísticas e relatórios técnicos.\nAplicação - Contém histórico de ações e aplicações dos projetos.\n\n\n\n\n\n\n\n\nComo será divido cada post ?\nEm 2001 para facilitar o entendimento dos profissionais da operação em industria eu escolhi um padrão que ao longo do tempo vem se mostrando eficiente e utilizarei aqui.\n\nO que é : qual a ideia do que está sendo abordado ?\nQual o objetivo : por que isso está sendo ou foi desenvolvido ?\nDe onde vem : quais as necessidades ou origem dessa demanda ? A motivação ?\nComo fazer : qual o procedimento, código, sequência ou fluxo ?\nPra onde vai : quem é o consumidor disso ? Qual a aplicação prática ?\nQual o resultado : descrição dos resultados previstos ou comprovados.\n\nReferencia: Transição demográfica Brasil e Japão"
  },
  {
    "objectID": "posts/welcome/index.html#como-serão-divididos-os-tópicos",
    "href": "posts/welcome/index.html#como-serão-divididos-os-tópicos",
    "title": "Motivação para o blog",
    "section": "Como serão divididos os tópicos ?",
    "text": "Como serão divididos os tópicos ?\n\nDemanda, definição do problema, objetivos e métricas de sucesso - Contém a origem e tipos de necessidade que é o que torna todo o restante do trabalho necessário.\nDados - Contém conceitos com o objetivo de estimular a observação, abstração e entendimento sobre o que são dados.\nFerramentas - Contém ferramentas como R(RStudio), Oracle SQL*plus, Oracle SNO, SPSS, Sphinx, Qlikview, PowerBI e excel.\nExploração - Contém visualização de dados, análise exploratória, tabelas, queries, planilhas de excel, folhas de verificação etc.\nModelos - Contém alguns tipos de modelos descritivos, preditivos, inferenciais, otimização entre outros.\nVersionamento e Reprodutibilidade - Contém processos para desenvolvimento de documentos reproduzíveis usando versionamento github, git, criação de documentos quarto_pub e rmardown, criação de livros bookdown entre outros.\nComunicação - Contém abordagens sobre comunicação das estatísticas e relatórios técnicos.\nAplicação - Contém histórico de ações e aplicações dos projetos."
  },
  {
    "objectID": "posts/welcome/index.html#como-será-divido-cada-post",
    "href": "posts/welcome/index.html#como-será-divido-cada-post",
    "title": "Motivação para o blog",
    "section": "Como será divido cada post ?",
    "text": "Como será divido cada post ?\nEm 2001 para facilitar o entendimento dos profissionais da operação em industria eu escolhi um padrão que ao longo do tempo vem se mostrando eficiente e utilizarei aqui.\n\nO que é : qual a ideia do que está sendo abordado ?\nQual o objetivo : por que isso está sendo ou foi desenvolvido ?\nDe onde vem : quais as necessidades ou origem dessa demanda ? A motivação ?\nComo fazer : qual o procedimento, código, sequência ou fluxo ?\nPra onde vai : quem é o consumidor disso ? Qual a aplicação prática ?\nQual o resultado : descrição dos resultados previstos ou comprovados.\n\nReferencia: Transição demográfica Brasil e Japão"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Sobre",
    "section": "Education",
    "text": "Education\n**Massachusetts Institute of Technology** | Cambridge, MA\nPh.D. in Computer Science | September 2009 - May 2014\n**The University of California, Berkeley** | Berkeley, CA\nB.S. in Computer Science | September 2005 - May 2009"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "Sobre",
    "section": "Experience",
    "text": "Experience\n**Google Brain** | Principal Investigator | January 2018 - Present\n**Netflix** | Research Scientist | June 2014 - December 2017"
  },
  {
    "objectID": "posts/post-with-code/index.html#qual-o-objetivo",
    "href": "posts/post-with-code/index.html#qual-o-objetivo",
    "title": "Avaliar resultados de modelo preditivo com matriz de confusão",
    "section": "Qual o objetivo",
    "text": "Qual o objetivo\n\nPor ser visual ajuda a responder rapidamente será que meu modelo teve um bom desempenho, onde deu errado, como posso corrigir ?\nAs diversas saídas de previõe permite a criação de indicadores que serão uteis nos ajustes mais adequados conforme a necessidade do trabalho que está sendo desenvolvido."
  },
  {
    "objectID": "posts/post-with-code/index.html#de-onde-vem-a-demanda",
    "href": "posts/post-with-code/index.html#de-onde-vem-a-demanda",
    "title": "Avaliar resultados de modelo preditivo com matriz de confusão",
    "section": "De onde vem a demanda",
    "text": "De onde vem a demanda\n\nEm 1904 Karl Pearson criou a tabela de contingência. Por que precisamos e uma matriz de confusao se tevem a acuracidade ?\nImagine prever quantas pessoas estao infectadas com um virus contagioso antes de apresentar sintomas e isola-las da populacao saudavel."
  },
  {
    "objectID": "posts/post-with-code/index.html#como-fazer",
    "href": "posts/post-with-code/index.html#como-fazer",
    "title": "Avaliar resultados de modelo preditivo com matriz de confusão",
    "section": "Como fazer",
    "text": "Como fazer\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\ntwo_class_example %>% filter(Class1 >0.5) %>% janitor::tabyl(truth)\n\n  truth   n   percent\n Class1 227 0.8194946\n Class2  50 0.1805054\n\ntwo_class_example %>% \n  janitor::tabyl(truth, predicted) %>% \n  janitor::adorn_totals(where = c(\"col\", \"row\")) %>% \n  janitor::adorn_title()\n\n        predicted             \n  truth    Class1 Class2 Total\n Class1       227     31   258\n Class2        50    192   242\n  Total       277    223   500\n\ntwo_class_example %>% \n  conf_mat(truth =truth, estimate =predicted, dnn =c(\"vlr_previsto\",\"vlr_real\"))\n\n            vlr_real\nvlr_previsto Class1 Class2\n      Class1    227     50\n      Class2     31    192\n\ntwo_class_example %>% \n  conf_mat(truth = truth, estimate = predicted) %>% \n  autoplot(type = \"heatmap\")\n\n\n\n#acuracia- prop de acertos do modelo total de acerto / total previu\ntwo_class_example %>% \n  accuracy(truth= truth, estimate = predicted)\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.838\n\n#sensibilidade chamada de recall. é a proporção de casos positivos que foram\n#identificados corretamente\n#Raio X de aeroporto prioriza sensitivity, diagnóstico de cancer\n#O não diagnóstico resulta em atraso no tratamento\n#mas um falso positivo resulta em ansiedade e testes invasivos como a biopsia\ntwo_class_example %>% \n  yardstick::sens(truth= truth, estimate = predicted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 sens    binary         0.880\n\n#Recall é uma métrica útil nos casos em que o Falso Negativo supera o falso positivol\n#é importante em casos médicos em que não importa se disparamos um alarme \n#falso, mas os casos positivos reais não devem passar despercebidos!\n#Em nosso exemplo, Recall seria uma métrica melhor porque não queremos dar alta \n#acidentalmente a uma pessoa infectada e deixá-la se misturar com a população \n#saudável,espalhando o vírus contagioso. \n#Agora você pode entender por que a acuracidade foi uma métrica ruim para modelo.\n\ntwo_class_example %>% \n  yardstick::recall(truth= truth, estimate = predicted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 recall  binary         0.880\n\ntwo_class_example %>% \n  yardstick::kap(truth= truth, estimate = predicted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 kap     binary         0.675\n\ntwo_class_example %>% \n  yardstick::npv(truth= truth, estimate = predicted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 npv     binary         0.861\n\ntwo_class_example %>% \n  yardstick::ppv(truth= truth, estimate = predicted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 ppv     binary         0.819\n\n#A precisão é util nos casos em que os falsos positivos são uma preocupação \n#maior do que os falsos negativos.\n#A precisão é importante em sistemas de recomendação de música ou vídeo, \n#sites de comércio eletrônico, etc. Resultados errados podem levar à perda de \n#clientes e prejudicar o negócio.\ntwo_class_example %>% \n  yardstick::precision(truth= truth, estimate = predicted)\n\n# A tibble: 1 × 3\n  .metric   .estimator .estimate\n  <chr>     <chr>          <dbl>\n1 precision binary         0.819\n\ntwo_class_example %>% \n  yardstick::spec(truth= truth, estimate = predicted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 spec    binary         0.793\n\ntwo_class_example %>% \n  roc_curve(truth = truth, estimate = Class1 ) %>% autoplot()\n\n\n\ntwo_class_example %>% \n  roc_auc(truth = truth, estimate = Class1 )\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.939\n\n\n\n\n\n\n\n\nDiferença entre incidência e prevalencia\n\n\n\nIncidencia é o número de casos recém-diagnosticados de uma doença. Número de novos casos de uma doença dividido pelo número de pessoas em risco para a doença. Se, ao longo de um ano, cinco mulheres são diagnosticadas com câncer de mama, de uma população total de 200 mulheres do estudo (que não têm câncer de mama no início do período de estudo), então diríamos que a incidência de câncer de mama câncer nesta população foi de 0,025. (ou 2.500 por 100.000 mulheres-anos de estudo)\nPrevalência é o número total de casos da doença existentes em uma população. A taxa de prevalência é o número total de casos de uma doença existente em uma população dividido pela população total. Assim, se uma medida de câncer é feita em uma população de 40.000 pessoas e 1.200 foram recentemente diagnosticadas com câncer e 3.500 estão vivendo com câncer, então a prevalência de câncer é de 0,118. (ou 11.750 por 100.000 pessoas)"
  },
  {
    "objectID": "posts/post-with-code/index.html#pra-onde-vai-quem-é-o-cliente",
    "href": "posts/post-with-code/index.html#pra-onde-vai-quem-é-o-cliente",
    "title": "Avaliar resultados de modelo preditivo com matriz de confusão",
    "section": "Pra onde vai quem é o cliente",
    "text": "Pra onde vai quem é o cliente\n- A próxima etapa é o ajuste, finalização e comunicação do modelo."
  },
  {
    "objectID": "posts/post-with-code/index.html#qual-o-resultado",
    "href": "posts/post-with-code/index.html#qual-o-resultado",
    "title": "Avaliar resultados de modelo preditivo com matriz de confusão",
    "section": "Qual o resultado",
    "text": "Qual o resultado\n- Aperfeiçoar\n- Facilitar\n- Melhorar"
  },
  {
    "objectID": "posts/post-with-code/index.html#diferença-entre-incidência-e-prevalencia",
    "href": "posts/post-with-code/index.html#diferença-entre-incidência-e-prevalencia",
    "title": "Avaliar resultados de modelo preditivo com matriz de confusão",
    "section": "Diferença entre incidência e prevalencia",
    "text": "Diferença entre incidência e prevalencia\nIncidencia é o número de casos recém-diagnosticados de uma doença. Número de novos casos de uma doença dividido pelo número de pessoas em risco para a doença. Se, ao longo de um ano, cinco mulheres são diagnosticadas com câncer de mama, de uma população total de 200 mulheres do estudo (que não têm câncer de mama no início do período de estudo), então diríamos que a incidência de câncer de mama câncer nesta população foi de 0,025. (ou 2.500 por 100.000 mulheres-anos de estudo)\nPrevalência é o número total de casos da doença existentes em uma população. A taxa de prevalência é o número total de casos de uma doença existente em uma população dividido pela população total. Assim, se uma medida de câncer é feita em uma população de 40.000 pessoas e 1.200 foram recentemente diagnosticadas com câncer e 3.500 estão vivendo com câncer, então a prevalência de câncer é de 0,118. (ou 11.750 por 100.000 pessoas) :::\n\nPra onde vai quem é o cliente\n\nA próxima etapa é o ajuste, finalização e comunicação do modelo.\n\n\n\nQual o resultado\n\nAperfeiçoar as técnicas de avaliação de performance de modelos poupando tempo e dinheiro.\nFacilitar o processo de busca por melhorias nos modelos de previsão.\nMelhorar a comunicação dos resultados."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "carvalho ribeiro blog",
    "section": "",
    "text": "Modelos\n\n\n\n\n\n\n\n\n\n\n\nAug 3, 2022\n\n\nMarcelo Carvalho dos Anjos\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nDemanda\n\n\nDados\n\n\nFerramentas\n\n\nExploração\n\n\nModelos\n\n\nVersionamento\n\n\nComunicação\n\n\nAplicação\n\n\n\n\n\n\n\n\n\n\n\nAug 3, 2022\n\n\nMarcelo Carvalho dos Anjos\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/dummy-post/post.html",
    "href": "posts/dummy-post/post.html",
    "title": "This is a dummy blog posts",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nam suscipit est nec dui eleifend, at dictum elit ullamcorper. Aliquam feugiat dictum bibendum. Praesent fermentum laoreet quam, cursus volutpat odio dapibus in. Fusce luctus porttitor vehicula. Donec ac tortor nisi. Donec at lectus tortor. Morbi tempor, nibh non euismod viverra, metus arcu aliquet elit, sed fringilla urna leo vel purus.\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nam suscipit est nec dui eleifend, at dictum elit ullamcorper. Aliquam feugiat dictum bibendum. Praesent fermentum laoreet quam, cursus volutpat odio dapibus in. Fusce luctus porttitor vehicula. Donec ac tortor nisi. Donec at lectus tortor. Morbi tempor, nibh non euismod viverra, metus arcu aliquet elit, sed fringilla urna leo vel purus.\n\n\nThis is inline code plus a small code chunk.\n\nlibrary(tidyverse)\nggplot(mpg) +\n  geom_jitter(aes(cty, hwy), size = 4, alpha = 0.5) \n\n\n\n\n\n\n\n\n\n\n\nTransforming OLS estimatesMaximizing likelihood\n\n\n\n\nCode\npreds_lm %>% \n  ggplot(aes(body_mass_g, bill_length_mm, col = correct)) +\n  geom_jitter(size = 4, alpha = 0.6) +\n  facet_wrap(vars(species)) +\n  scale_color_manual(values = c('grey60', thematic::okabe_ito(3)[3])) +\n  scale_x_continuous(breaks = seq(3000, 6000, 1000)) +\n  theme_minimal(base_size = 12) +\n  theme(\n    legend.position = 'top', \n    panel.background = element_rect(color = 'black'),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(\n    x = 'Body mass (in g)',\n    y = 'Bill length (in mm)'\n  )\n\n\n\n\n\n\n\n\n\nCode\nglm.mod <- glm(sex ~ body_mass_g + bill_length_mm + species, family = binomial, data = dat)\npreds <- dat %>% \n  mutate(\n    prob.fit = glm.mod$fitted.values,\n    prediction = if_else(prob.fit > 0.5, 'male', 'female'),\n    correct = if_else(sex == prediction, 'correct', 'incorrect')\n  )\npreds %>% \n  ggplot(aes(body_mass_g, bill_length_mm, col = correct)) +\n  geom_jitter(size = 4, alpha = 0.6) +\n  facet_wrap(vars(species)) +\n  scale_x_continuous(breaks = seq(3000, 6000, 1000)) +\n  scale_color_manual(values = c('grey60', thematic::okabe_ito(3)[3])) +\n  theme_minimal(base_size = 10) +\n  theme(\n    legend.position = 'top', \n    panel.background = element_rect(color = 'black'),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(\n    x = 'Body mass (in g)',\n    y = 'Bill length (in mm)'\n  )\n\n\n\n\n\n\n\n\n\n\n\\[\n\\int_0^1 f(x) \\ dx\n\\]\n\n\n\n\n\n\n\n\ngeom_density(\n  mapping = NULL,\n  data = NULL,\n  stat = \"density\",\n  position = \"identity\",\n  ...,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  outline.type = \"upper\"\n)\n\n\nstat_density(\n  mapping = NULL,\n  data = NULL,\n  geom = \"area\",\n  position = \"stack\",\n  ...,\n  bw = \"nrd0\",\n  adjust = 1,\n  kernel = \"gaussian\",\n  n = 512,\n  trim = FALSE,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE\n)\n\n\n\n\n\n\n#| fig-cap: “Bla bla bla. This is a caption in the margin. Super cool isn’t it?” #| fig-cap-location: margin ggplot(data = gapminder::gapminder, mapping = aes(x = lifeExp, fill = continent)) + stat_density(position = “identity”, alpha = 0.5)"
  },
  {
    "objectID": "posts/confusion-matrix/index.html",
    "href": "posts/confusion-matrix/index.html",
    "title": "Avaliar resultados de modelo preditivo com matriz de confusão",
    "section": "",
    "text": "Qual o objetivo\n\nPor ser visual ajuda a responder rapidamente será que meu modelo teve um bom desempenho, onde deu errado, como posso corrigir ?\nAs diversas saídas de previõe permite a criação de indicadores que serão uteis nos ajustes mais adequados conforme a necessidade do trabalho que está sendo desenvolvido.\n\n\n\nDe onde vem a demanda\n\nEm 1904 Karl Pearson criou a tabela de contingência. Por que precisamos e uma matriz de confusao se tevem a acuracidade ?\nImagine prever quantas pessoas estao infectadas com um virus contagioso antes de apresentar sintomas e isola-las da populacao saudavel.\n\n\n\nComo fazer\nPara reproduzir os códigos abaixo serão necessários os pacotes tidyverse , tidymodels e janitor\nO principal pacote que será usando para analisar uma matriz de confusão é o pacote yardstick que já é carregado quando chamamos o pacote tidymodels.\n\n#packages\nlibrary(tidyverse)\nlibrary(tidymodels)\n\n#check\ntwo_class_example %>% filter(Class1 >0.5) %>% janitor::tabyl(truth)\n\n  truth   n   percent\n Class1 227 0.8194946\n Class2  50 0.1805054\n\n#exemplo de tabela cruzada usando janitor\ntwo_class_example %>% \n  janitor::tabyl(truth, predicted) %>% \n  janitor::adorn_totals(where = c(\"col\", \"row\")) %>% \n  janitor::adorn_title()\n\n        predicted             \n  truth    Class1 Class2 Total\n Class1       227     31   258\n Class2        50    192   242\n  Total       277    223   500\n\n#trocando nomes\ntwo_class_example %>% \n  conf_mat(truth =truth, estimate =predicted, dnn =c(\"vlr_previsto\",\"vlr_real\"))\n\n            vlr_real\nvlr_previsto Class1 Class2\n      Class1    227     50\n      Class2     31    192\n\n#plot heatmap\ntwo_class_example %>% \n  conf_mat(truth = truth, estimate = predicted) %>% \n  autoplot(type = \"heatmap\")\n\n\n\n#acuracia- prop de acertos do modelo total de acerto / total previu\ntwo_class_example %>% \n  accuracy(truth= truth, estimate = predicted)\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.838\n\n#sensibilidade ou recall é a proporção de casos positivos classif corretamente\n#Raio X de aeroporto prioriza sensitivity\n#diagnóstico de cancer também pois o não diagnóstico resulta em atraso no tratamento\ntwo_class_example %>% \n  yardstick::sens(truth= truth, estimate = predicted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 sens    binary         0.880\n\n#Recall métrica útil nos casos em que o Falso Negativo supera o falso positivol\n#importante em casos médicos em que não importa se disparamos um alarme \n#falso, mas os casos positivos reais não devem passar despercebidos!\n#Em nosso exemplo, Recall seria uma métrica melhor porque não queremos dar alta \n#acidentalmente a uma pessoa infectada e deixá-la se misturar com a população \n#saudável,espalhando o vírus contagioso. \n#Agora você pode entender por que a acuracidade foi uma métrica ruim para modelo.\ntwo_class_example %>% \n  yardstick::recall(truth= truth, estimate = predicted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 recall  binary         0.880\n\n#kappa\ntwo_class_example %>% \n  yardstick::kap(truth= truth, estimate = predicted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 kap     binary         0.675\n\n#npv\ntwo_class_example %>% \n  yardstick::npv(truth= truth, estimate = predicted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 npv     binary         0.861\n\n#ppv\ntwo_class_example %>% \n  yardstick::ppv(truth= truth, estimate = predicted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 ppv     binary         0.819\n\n#A precisão é util nos casos em que os falsos positivos são uma preocupação \n#maior do que os falsos negativos.\n#A precisão é importante em sistemas de recomendação de música ou vídeo, \n#sites de comércio eletrônico, etc. Resultados errados podem levar à perda de \n#clientes e prejudicar o negócio.\ntwo_class_example %>% \n  yardstick::precision(truth= truth, estimate = predicted)\n\n# A tibble: 1 × 3\n  .metric   .estimator .estimate\n  <chr>     <chr>          <dbl>\n1 precision binary         0.819\n\n#spec\ntwo_class_example %>% \n  yardstick::spec(truth= truth, estimate = predicted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 spec    binary         0.793\n\n#roc_curve\ntwo_class_example %>% \n  roc_curve(truth = truth, estimate = Class1 ) %>% autoplot()\n\n\n\n#roc_auc\ntwo_class_example %>% \n  roc_auc(truth = truth, estimate = Class1 )\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.939\n\n\n\n\n\n\n\n\nDiferença entre incidência e prevalencia\n\n\n\n\n\nIncidencia é o número de casos recém-diagnosticados de uma doença. Número de novos casos de uma doença dividido pelo número de pessoas em risco para a doença. Se, ao longo de um ano, cinco mulheres são diagnosticadas com câncer de mama, de uma população total de 200 mulheres do estudo (que não têm câncer de mama no início do período de estudo), então diríamos que a incidência de câncer de mama câncer nesta população foi de 0,025. (ou 2.500 por 100.000 mulheres-anos de estudo)\nPrevalência é o número total de casos da doença existentes em uma população. A taxa de prevalência é o número total de casos de uma doença existente em uma população dividido pela população total. Assim, se uma medida de câncer é feita em uma população de 40.000 pessoas e 1.200 foram recentemente diagnosticadas com câncer e 3.500 estão vivendo com câncer, então a prevalência de câncer é de 0,118. (ou 11.750 por 100.000 pessoas)\n\n\n\n\n\nPra onde vai quem é o cliente\n\nA próxima etapa é o ajuste, finalização e comunicação do modelo.\n\n\n\nQual o resultado\n\nAperfeiçoar as técnicas de avaliação de performance de modelos poupando tempo e dinheiro.\nFacilitar o processo de busca por melhorias nos modelos de previsão.\nMelhorar a comunicação dos resultados."
  },
  {
    "objectID": "posts/neural-net-nnet/neuralnet.html",
    "href": "posts/neural-net-nnet/neuralnet.html",
    "title": "Modelo preditivo usando com rede neural",
    "section": "",
    "text": "Qual o objetivo\n\nA técnica é muito utilizada na solução de problemas de classificação onde o resultado(desfecho) é uma classe (e.g. gato, cachorro, cavalo).\nNeste exemplo, nós usaremos como exemplo uma linha de produção com sensores que registram características como largura e comprimento da pétala e sepala dos três tipos de flores iris: setosa, versicolor e virgínica.\nNosso objetivo é fazer um modelo de previsão o qual com base nessas características, consiga classificar cada tipo de flor e separá-las corretamente.\n\n\n\nDe onde vem a demanda\n\nVem do uso de sistemas que utilizam visão computacional, processamento de linguagem natural em seu funcionamento como por exemplo veículos semi-autonomos, linhas de produção de veículos, controle de qualidade de autopeças entre outros.\nA primeira rede neural artificial foi implementada em 1958 por Frank Rosenblat e se chamava Perceptron e naquela época já se falava que era um embrião de um computador eletronico que seria capaz de andar, falar, ver, escrever e se reproduzir. Materia New York Times\n\n\n\nComo fazer\nNeste exemplo usaremos os pacotes tidyverse, janitor, tidymodels, nnet e neuralnettools\n\n# packages ----------------------------------------------------\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(nnet)\nlibrary(NeuralNetTools)\n\n# data --------------------------------------------------------\ndata_iris <- iris %>% janitor::clean_names()\n\nsplit_iris <- initial_split(data_iris, strata = species)\ntrain_iris <- training(split_iris)\ntest_iris  <- testing(split_iris)\n\n# model -------------------------------------------------------\nmdl_fit_nn_iris <- nnet(species ~., \n                        data = train_iris, \n                        size = 5, \n                        decay = 0.01, \n                        maxit = 500)\n\n# weights:  43\ninitial  value 137.813369 \niter  10 value 40.287271\niter  20 value 10.098038\niter  30 value 9.419960\niter  40 value 9.054851\niter  50 value 8.772584\niter  60 value 8.746655\niter  70 value 8.734800\niter  80 value 8.731859\niter  90 value 8.731220\niter 100 value 8.730121\niter 110 value 8.729871\niter 120 value 8.729699\niter 130 value 8.729660\niter 140 value 8.729656\niter 140 value 8.729656\niter 140 value 8.729656\nfinal  value 8.729656 \nconverged\n\n\nVamos fazer uma previsão usando o modelo que construímos e colocar o resultado dentro do dataframe com os dados de teste para podermos comparar valores previstos e realizados.\n\n# results -----------------------------------------------------\nmdl_fit_nn_iris %>% \n  predict(test_iris,type = \"class\") %>%\n  bind_cols(test_iris)\n\nNew names:\n• `` -> `...1`\n\n\n         ...1 sepal_length sepal_width petal_length petal_width    species\n1      setosa          4.9         3.0          1.4         0.2     setosa\n2      setosa          5.0         3.6          1.4         0.2     setosa\n3      setosa          5.4         3.9          1.7         0.4     setosa\n4      setosa          5.0         3.4          1.5         0.2     setosa\n5      setosa          4.9         3.1          1.5         0.1     setosa\n6      setosa          4.8         3.0          1.4         0.1     setosa\n7      setosa          4.3         3.0          1.1         0.1     setosa\n8      setosa          5.4         3.4          1.7         0.2     setosa\n9      setosa          5.1         3.7          1.5         0.4     setosa\n10     setosa          5.2         4.1          1.5         0.1     setosa\n11     setosa          4.4         3.0          1.3         0.2     setosa\n12     setosa          4.8         3.0          1.4         0.3     setosa\n13     setosa          5.3         3.7          1.5         0.2     setosa\n14 versicolor          6.3         3.3          4.7         1.6 versicolor\n15 versicolor          6.0         2.2          4.0         1.0 versicolor\n16 versicolor          5.8         2.7          4.1         1.0 versicolor\n17 versicolor          6.2         2.2          4.5         1.5 versicolor\n18 versicolor          5.7         2.6          3.5         1.0 versicolor\n19 versicolor          5.5         2.4          3.8         1.1 versicolor\n20 versicolor          5.8         2.7          3.9         1.2 versicolor\n21 versicolor          5.4         3.0          4.5         1.5 versicolor\n22 versicolor          6.0         3.4          4.5         1.6 versicolor\n23 versicolor          5.5         2.5          4.0         1.3 versicolor\n24 versicolor          5.5         2.6          4.4         1.2 versicolor\n25 versicolor          5.6         2.7          4.2         1.3 versicolor\n26 versicolor          5.1         2.5          3.0         1.1 versicolor\n27  virginica          6.3         3.3          6.0         2.5  virginica\n28  virginica          7.1         3.0          5.9         2.1  virginica\n29  virginica          4.9         2.5          4.5         1.7  virginica\n30  virginica          7.2         3.6          6.1         2.5  virginica\n31  virginica          5.7         2.5          5.0         2.0  virginica\n32  virginica          5.6         2.8          4.9         2.0  virginica\n33  virginica          7.7         2.8          6.7         2.0  virginica\n34  virginica          7.4         2.8          6.1         1.9  virginica\n35  virginica          7.9         3.8          6.4         2.0  virginica\n36  virginica          6.4         3.1          5.5         1.8  virginica\n37  virginica          5.8         2.7          5.1         1.9  virginica\n38  virginica          6.3         2.5          5.0         1.9  virginica\n39  virginica          6.2         3.4          5.4         2.3  virginica\n\n\nComo já temos o resultados previstos e o real, podemos fazer uma matriz de confusão para facilitar a visualização dos resultados e analisar o desempenho inicial do modelo.\n\n#confusion matrix\ntable(test_iris$species,\n      predict(mdl_fit_nn_iris,\n              newdata = test_iris, \n              type = \"class\"))\n\n            \n             setosa versicolor virginica\n  setosa         13          0         0\n  versicolor      0         13         0\n  virginica       0          0        13\n\n\nComo ficou o resultado da previsão ?\n\n#predict classes\npredict(mdl_fit_nn_iris, test_iris, type = \"class\")\n\n [1] \"setosa\"     \"setosa\"     \"setosa\"     \"setosa\"     \"setosa\"    \n [6] \"setosa\"     \"setosa\"     \"setosa\"     \"setosa\"     \"setosa\"    \n[11] \"setosa\"     \"setosa\"     \"setosa\"     \"versicolor\" \"versicolor\"\n[16] \"versicolor\" \"versicolor\" \"versicolor\" \"versicolor\" \"versicolor\"\n[21] \"versicolor\" \"versicolor\" \"versicolor\" \"versicolor\" \"versicolor\"\n[26] \"versicolor\" \"virginica\"  \"virginica\"  \"virginica\"  \"virginica\" \n[31] \"virginica\"  \"virginica\"  \"virginica\"  \"virginica\"  \"virginica\" \n[36] \"virginica\"  \"virginica\"  \"virginica\"  \"virginica\" \n\n\nPlotando o modelo que acabamos de fazer\n\n#plotando o gráfico\nNeuralNetTools::plotnet(mdl_fit_nn_iris,pad_x=0.55, circle_col = \"grey90\")\n\n\n\n\n\n\nPra onde vai quem é o cliente\n\nUm modelos de previsão de classificação pode ser embarcado dentro do sistema de produção.\nO modelo que fizemos é bastante simples e serve apenas como base para aprendizado, como próximo passo o uso de validação cruzada (cross validation) pode ser uma excelente opção para complementar o que aprendemos aqui.\n\n\n\nQual o resultado\n\nAperfeiçoar as técnicas de contrução de modelos e solução de problemas de classificação para que estes possam auxiliar na produtividade da industria de flores que usamos como exemplo.\nFacilitar o processo de classificação.\nMelhorar o processo de produção, qualidade do produto, satisfação do consumidor e competitividade do negócio."
  },
  {
    "objectID": "posts/importar-visualizar/importar_visualizar.html",
    "href": "posts/importar-visualizar/importar_visualizar.html",
    "title": "Como importar e visualizar dados - Titanic dataset parte1",
    "section": "",
    "text": "O que é importação e visualização de dados\n\nÉ a etapa onde é feita extração de dados e avaliação se os mesmos podem contribuir para a solução do problema a ser resolvido.\nA visualização é uma forma intuitiva de traçar relações possíveis entre os dados e o desfecho permitindo a geração de questões e levantamento de hipóteses.\nGeralmente estão atrelados a uma métrica de sucesso e é feito após a etapa P do PDCA , PPDAC ou outro método de análise de fenõmeno e causa raíz utilizado.\n\n\n\nProcesso de projeto kaizen\n\n\n\n\n\nQual o objetivo\n\nDisponibilizar recursos revelantes para solução dos problemas\nFiltrar dados relevantes dos não relevantes, entender a natureza dos dados se são realmente ruídos ou carecem de representação.\nAvaliar existencia de shadow stats ou se haverá dificuldade na coleta. Por exemplo: o dado pode ser muito relevante mas difícil de ser coletado ou pode haver muita instabilidade e ambiguidade ou até mesmo usar critérios diferentes entre diferentes fontes.\nGerar novas questões e hipóteses que poderão utilizar novos dados ou um resultado de interação entre os existentes.\n\n\n\nDe onde vem a demanda\n\nA extração e visualização dos dados vem da necessidade de encontrar variáveis que expliquem o fenômeno e ajudem a prever eventos futuros.\nMelhorar e estimular a geração de ideias através da interação entre os envolvidos.\n\n\n\nComo fazer\nPara reproduzir os códigos abaixo serão necessários os pacotes tidyverse , tidymodels e janitor, ggpubr, funmodeling, ggalluvial e visdat\n\nO dados podem ser baixados no Kaggle titanic dataset\n\n# pacotes           --------------------------------------------------------\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(ggpubr)\nlibrary(funModeling)\nlibrary(ggalluvial)\nlibrary(visdat)\n\n# dados             --------------------------------------------------------\n#importar os dados do kaggle e salvar em  diretorio padrão\n\n# importar dados e padronizar colunas\ntrain_titanic <- \n    read.csv(\"train.csv\", na.strings = c(\"\",\" \")) %>% \n    clean_names() %>% \n    mutate(is_train = TRUE) \n\n#importar dados de teste\ntest_titanic <- \n  read.csv(\"test.csv\", na.strings = c(\"\",\" \")) %>% \n  clean_names() %>% \n  mutate(survived = NA, is_train = FALSE) \n\n#juntar os conjuntos\nsplit_titanic <- bind_rows(train_titanic, test_titanic)\n\n#check nas caracteristicas dos dados\nsplit_titanic %>% funModeling::df_status()\n\n       variable q_zeros p_zeros q_na  p_na q_inf p_inf      type unique\n1  passenger_id       0    0.00    0  0.00     0     0   integer   1309\n2      survived     549   41.94  418 31.93     0     0   integer      2\n3        pclass       0    0.00    0  0.00     0     0   integer      3\n4          name       0    0.00    0  0.00     0     0 character   1307\n5           sex       0    0.00    0  0.00     0     0 character      2\n6           age       0    0.00  263 20.09     0     0   numeric     98\n7        sib_sp     891   68.07    0  0.00     0     0   integer      7\n8         parch    1002   76.55    0  0.00     0     0   integer      8\n9        ticket       0    0.00    0  0.00     0     0 character    929\n10         fare      17    1.30    1  0.08     0     0   numeric    281\n11        cabin       0    0.00 1014 77.46     0     0 character    186\n12     embarked       0    0.00    2  0.15     0     0 character      3\n13     is_train     418   31.93    0  0.00     0     0   logical      2\n\n\nComo o nosso conjunto de dados é pequeno(tem poucas variáveis) é possível usar um gráfico para visualizar os tipos de dados e as características.\n\nsplit_titanic %>% visdat::vis_dat()\n\n\n\n\n\n\n\n\n\n\nComo faço pra visualizar dados faltantes quando o conjunto for grande ?\n\n\n\n\n\nSugestão É possível usar o pacote naniar com a função naniar::miss_var_summary()\n\n\n\nComo resultado da análise podemos verificar a necessidade de algumas transformações nos dados. Anotamos tudo para alterarmos posteriormente mas seguimos com a análise exploratória por enquanto.\n\nAlterar o tipo de variável de sex, embarked, survived, pclass = factor\nInserir dados faltantes em embarked = moda, age e fare = usando knn\n\nVamos fazer uma correlação para avaliar os padrões existentes. Mas note. Para fazer correlação, os dados precisam ser numéricos por isso usamos a função select_if(is.numeric) . Pelo padrão apresentado é possível verificar a existencia de dados categóricos eles geralmente ficam espaçados no gráfico e eles precisam ser transformados pra factor posteriormente e que já anotamos e comunicamos.\n\n# correlacao\ntrain_titanic %>% \n  select_if(is.numeric) %>% \n  GGally::ggscatmat(color = \"survived\", corMethod = \"spearman\")+\n  theme_pubclean()\n\n\n\n\nSerá que a idade importa ?\n\n# age - será que a idade importa ? \ntrain_titanic %>% \n  ggplot(aes(x=age, fill = factor(survived)))+\n  geom_density(alpha =0.5)\n\n\n\n\nSerá que o sexo importa ?\n\n# age, sex and class - será que o sexo importa ?\ntrain_titanic %>% \n  ggplot(aes(x=pclass, fill= factor(survived)))+\n  geom_bar(stat = \"count\")+\n  facet_grid(~sex)\n\n\n\n\nVamos juntar as variáveis age+sex+pclass e analisar sob outro ponto de vista\n\n# age sex and class - sob outro ponto de vista\ntrain_titanic %>% \n  ggplot(aes(x=age, y=sex))+\n  geom_jitter(aes(color = factor(survived)))+\n  facet_wrap(~pclass)\n\n\n\n\nNovamente vamos analisar sob outro ponto de vista\n\n# sex, class e survived \ntrain_titanic %>% \n  group_by(sex, survived, pclass) %>% \n  summarise(qtd = n()) %>% \n  ggplot(aes(axis1=sex, axis2=pclass, axis3 = survived, y=qtd, fill= sex))+\n  geom_alluvium()+\n  geom_stratum()+\n  geom_text(stat = \"stratum\", aes(label = after_stat(stratum)))+\n  scale_x_discrete(limits = c(\"sex\", \"pclass\",\"survived\"))\n\n\n\n\nSerá que a variável tarifa está bem representada ?\n\n# fare - será que fare é uma variável válida ?\ntrain_titanic %>% \n  mutate(fare = fare) %>% \n  ggplot(aes(x=fare, y=pclass))+\n  geom_jitter(aes(color = factor(survived)))\n\n\n\n\nSera que o tamanho da familia importa e o dado está bem representado ?\n\n# parch sib_sp - será que o tamanho da familia importa ?\ntrain_titanic %>% \n  mutate(family_size = parch + sib_sp +1) %>%\n  ggboxplot(x=\"survived\", \n            y=\"family_size\", \n            fill= \"survived\",\n            palette = \"uchicago\")+\n  stat_compare_means()\n\n\n\n\nSerá que existe algum padrão no nome que possa ser extraído e que ajude a explicar se impacta na sobrevivência ?\n\n# title\ntrain_titanic %>% \n  mutate(title = str_extract(name, \"[A-z]*\\\\.\")) %>% \n  tabyl(title) %>% \n  adorn_pct_formatting() %>% \n  arrange(desc(n))\n\n     title   n percent\n       Mr. 517   58.0%\n     Miss. 182   20.4%\n      Mrs. 125   14.0%\n   Master.  40    4.5%\n       Dr.   7    0.8%\n      Rev.   6    0.7%\n      Col.   2    0.2%\n    Major.   2    0.2%\n     Mlle.   2    0.2%\n     Capt.   1    0.1%\n Countess.   1    0.1%\n      Don.   1    0.1%\n Jonkheer.   1    0.1%\n     Lady.   1    0.1%\n      Mme.   1    0.1%\n       Ms.   1    0.1%\n      Sir.   1    0.1%\n\n\n\n\nPra onde vai quem é o cliente\n\nA próxima etapa é comunicar os resultados junto aos membros do projeto sobre as relações encontradas permitindo a interção e levantamento de novas necessidades ou hipóteses.\nPosteriormente, vem as etapas de pré processamento, modelo, validação e submissão.\n\n\n\nQual o resultado\n\nAperfeiçoar a técnica de observação e representação de dados.\nFacilitar a comunicação com os envolvidos no projeto.\nMelhorar e estimular a geração de ideias através da interação entre os membros do projeto."
  }
]