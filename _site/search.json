[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Info",
    "section": "",
    "text": "Goals\nO objetivo do blog é complementar o conteúdo postado no YouTube e tentar facilitar a vida do pesquisador, melhorista de processo e demais profissionais da industria e setor de serviços.\n\n\n Education\nNova Acrópole | Florianópolis, SC, Brasil\nFilosofia na tradição Clássica | 2014-2015\nUniversidade Uniderp | Campo Grande, MS, Brasil\nMestrado Produção e Gestão Agroindustrial | 2008-2010"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Carvalho Ribeiro Blog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nComunicar trabalhos técnicos em apresentações no R com Quarto\n\n\nComunicar resultados no formato apresentação de slides em reveljs\n\n\n\n\nComunicação\n\n\n\n\n\n\n\n\n\n\n\nJul 16, 2023\n\n\nMarcelo Carvalho dos Anjos\n\n\n\n\n\n\n  \n\n\n\n\nModelo preditivo | tidymodels decision tree rpart diabetes\n\n\nModelo machine learning de árvore de decisão usando rpart, tidymodels e dados de diabetes\n\n\n\n\nModelos\n\n\n\n\n\n\n\n\n\n\n\nNov 29, 2022\n\n\nMarcelo Carvalho dos Anjos\n\n\n\n\n\n\n  \n\n\n\n\nComo comunicar dados em artigos técnicos no R - Quarto\n\n\n\n\n\n\n\nComunicação\n\n\n\n\n\n\n\n\n\n\n\nOct 24, 2022\n\n\nMarcelo Carvalho dos Anjos\n\n\n\n\n\n\n  \n\n\n\n\nComo construir gráficos para artigo técnico\n\n\n\n\n\n\n\nExploração\n\n\nComunicação\n\n\n\n\n\n\n\n\n\n\n\nSep 28, 2022\n\n\nMarcelo Carvalho dos Anjos\n\n\n\n\n\n\n  \n\n\n\n\nComo construir tabela para artigo técnico - gtsummary\n\n\n\n\n\n\n\nExploração\n\n\nModelos\n\n\n\n\n\n\n\n\n\n\n\n\nSep 12, 2022\n\n\nMarcelo Carvalho dos Anjos\n\n\n\n\n\n\n  \n\n\n\n\nComo Identificar padrões em dados - gráfico de dispersão\n\n\n\n\n\n\n\nExploração\n\n\n\n\n\n\n\n\n\n\n\nAug 28, 2022\n\n\nMarcelo Carvalho dos Anjos\n\n\n\n\n\n\n  \n\n\n\n\nComo analisar distribuição em dados - histograma curva normal\n\n\n\n\n\n\n\nExploração\n\n\n\n\n\n\n\n\n\n\n\nAug 21, 2022\n\n\nMarcelo Carvalho dos Anjos\n\n\n\n\n\n\n  \n\n\n\n\nComo importar e visualizar dados - Titanic dataset parte1\n\n\n\n\n\n\n\nExploração\n\n\n\n\n\n\n\n\n\n\n\nAug 7, 2022\n\n\nMarcelo Carvalho dos Anjos\n\n\n\n\n\n\n  \n\n\n\n\nModelo preditivo usando com rede neural\n\n\n\n\n\n\n\nModelos\n\n\n\n\n\n\n\n\n\n\n\nAug 6, 2022\n\n\nMarcelo Carvalho dos Anjos\n\n\n\n\n\n\n  \n\n\n\n\nAvaliar resultados de modelo preditivo com matriz de confusão\n\n\n\n\n\n\n\nModelos\n\n\n\n\n\n\n\n\n\n\n\nAug 3, 2022\n\n\nMarcelo Carvalho dos Anjos\n\n\n\n\n\n\n  \n\n\n\n\nMotivação para o blog\n\n\n\n\n\n\n\nDemanda\n\n\nDados\n\n\nFerramentas\n\n\nExploração\n\n\nModelos\n\n\nVersionamento\n\n\nComunicação\n\n\nAplicação\n\n\n\n\n\n\n\n\n\n\n\nAug 3, 2022\n\n\nMarcelo Carvalho dos Anjos\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/chart_stats/plot_stats.html",
    "href": "posts/chart_stats/plot_stats.html",
    "title": "Como construir gráficos para artigo técnico",
    "section": "",
    "text": "O que é um gráfico\n\nUm meio eficiente de representação e comunicação de dados e pode conter uma quantidade de significativa de informação.\nFormato visual de representação de dados que é interpretado em grande velocidade pelo cerebro e que permite ações ou decisões mais rápidas.\n\n\n\n\nAlguns tipos de gráficos\n\n\n\n\n Qual o objetivo\n\nFacilitar a identificação de padrões, tendências e discrepancias nos dados transformando em informações.\nPermitir ações imediatas ou gerar informação complementar para que ações possam ser tomadas posteriormente.\n\n\n\n De onde vem a demanda\n\nNecessidade de representação de dados que potencialize o desenvolvimento de estratégias e ações.\nNecessidade de algo que fortaleça o argumento em um estudo ou pesquisa.\n\n\n\n Como fazer\nPara reproduzir os códigos abaixo serão necessários os pacotes tidyverse , ggpmisc, janitor, qcc, ggpubr, ggQC, quantmod e ggalluvial\n\nlibrary(tidyverse)\nlibrary(ggpubr)\nlibrary(ggpmisc)\nlibrary(qcc)\nlibrary(ggQC)\nlibrary(quantmod)\nlibrary(easyalluvial)\n\nGráfico de comparação\n\ngroup_compar1 <- \n  list(c(\"4\",\"6\"),\n       c(\"6\",\"8\"),\n       c(\"4\",\"8\"))\n\nmtcars %>% \n  ggboxplot(x = \"cyl\",\n            y= \"mpg\",\n            fill = \"cyl\",\n            palette = \"uchicago\")+\n  stat_compare_means(comparisons = group_compar1)\n\n\n\n\nPlotando estatístics no corpo do gráfico.\n\nmtcars %>% \n  ggplot(aes(x = wt, y = mpg))+\n  geom_point()+\n  stat_fit_tb(method = \"lm\",\n              label.x = \"right\",\n              method.args = list(formula = y~x),\n              table.theme = ttheme_gtdark())\n\n\n\n\nPlotando fórmulas no corpo do gráfico.\n\nmtcars %>% \n  ggplot(aes(x = wt, y = mpg))+\n  geom_point()+\n  stat_correlation(use_label(c(\"r\", \"t\", \"p\")),\n                   label.x = \"right\")\n\n\n\n\nPlotando dados no corpo do gráfico.\n\ntbl_median_mtcars <- \n  mtcars %>% \n  select(mpg, hp, cyl) %>% \n  group_by(cyl) %>% \n  summarise(across(where(is.numeric), median)) %>% \n  ungroup()\n\ndata_trans_mtcars <- tibble(x = 5.40, y = 34, tb = list(tbl_median_mtcars))\n\nmtcars %>% \n  ggplot(aes(x = wt, y = mpg, color = factor(cyl)))+\n  geom_point()+\n  geom_table(data= data_trans_mtcars, aes(x=x, y=y, label = tb))\n\n\n\n\nGráfico de cause efeito.\n\nqcc::cause.and.effect(\n  cause = list(\n    medida = c(\"metrica errada\"),\n    maquin = c(\"defeito\"),\n    metodo = c(\"treinamento\")\n      ),\n  effect = \"efeito\"\n)\n\n\n\n\nModelo para auxiliar na escolha de gráfico de controle.\n\n\n\n\nflowchart LR\n    A[dados] -->B{qual tipo \\n de dados?}\n    B -->C[Contínuo]\n    B -->D[Discreta/\\nAtributos]\n    C -->E{Qual o volume\\n de dados ?}\n    E -->|n = 1|F[x.one + R]\n    E -->|n 2-10|G[x + R]\n    E -->|n > 10|H[x + S]\n    D -->I{Lote de dados\\n constante ?}\n    I-->J[Sim]\n    I-->K[Não]\n    J-->L[C Proporção de \\ndefeitos por UN]\n    J-->M[NP Contagem de \\ndefeitos por UN]\n    K-->N[U Contagem de \\ndefeitos por UN]\n    K-->O[P Proporção de \\ndefeitos por UN]\n\n\n\n\n\n\n\n\nGráfico X bar de controle de processo.\n\ndata(\"pistonrings\")\n\ndata_pistonring <- as_tibble(pistonrings)\n\nqcc(data_pistonring$diameter,\n                type = \"xbar.one\",\n                rules = shewhart.rules)\n\n\n\n\nList of 11\n $ call      : language qcc(data = data_pistonring$diameter, type = \"xbar.one\", rules = shewhart.rules)\n $ type      : chr \"xbar.one\"\n $ data.name : chr \"data_pistonring$diameter\"\n $ data      : num [1:200, 1] 74 74 74 74 74 ...\n  ..- attr(*, \"dimnames\")=List of 2\n $ statistics: Named num [1:200] 74 74 74 74 74 ...\n  ..- attr(*, \"names\")= chr [1:200] \"1\" \"2\" \"3\" \"4\" ...\n $ sizes     : int [1:200] 1 1 1 1 1 1 1 1 1 1 ...\n $ center    : num 74\n $ std.dev   : num 0.01\n $ nsigmas   : num 3\n $ limits    : num [1, 1:2] 74 74\n  ..- attr(*, \"dimnames\")=List of 2\n $ violations:List of 2\n - attr(*, \"class\")= chr \"qcc\"\n\n\nGráfico de pareto.\n\ndata_defeito <- \n  tribble(~\"tipo\", ~\"qtd\", ~\"custo\",\n          \"riscos\", 201, 4287.60,\n          \"Manchas\",78,2423.46,\n          \"Dobras\",47,1118.60,\n          \"Furos\",31,8946.60,\n          \"Rasgos\",15,1864.05)\n\npareto_defeito <- \n  data_defeito %>% \n  ggplot(aes(x = tipo, y= qtd))+\n  stat_pareto(bars.fill = \"lightblue\")\n\npareto_custo <- \n  data_defeito %>% \n  ggplot(aes(x = tipo, y= custo))+\n  stat_pareto(bars.fill = \"navy\")\n\ndata_defeito %>% \n  ggplot(aes(x = tipo, y = custo))+\n  stat_pareto(bars.fill = \"navy\")+\n  annotate(\"plot_npc\", \n            npcx = \"right\", \n            npcy = \"middle\",\n            label =pareto_defeito )\n\n\n\n\nGráfico de sentimento candlestick chart.\n\ngetSymbols(\"MORTGAGE30US\", src= \"FRED\")\n\n[1] \"MORTGAGE30US\"\n\nchart_Series(MORTGAGE30US)\n\n\n\ngetSymbols(\"VIXCLS\", src= \"FRED\")\n\n[1] \"VIXCLS\"\n\nchart_Series(VIXCLS)\n\n\n\ngetSymbols(\"DGS10\", src= \"FRED\")\n\n[1] \"DGS10\"\n\nchart_Series(DGS10)\n\n\n\ngetSymbols(\"VALE\")\n\n[1] \"VALE\"\n\nchartSeries(VALE)\n\n\n\n\nGráfico de análise multidimensional Alluvial.\n\nplot_mtcars <- \n  mtcars %>% \n  alluvial_wide(max_variables = 5) \n  \nadd_marginal_histograms(plot_mtcars, mtcars)\n\n\n\n\nGráfico PCA\n\niris %>% \n  select(-Species) %>% \n  prcomp(center = TRUE, scale. = TRUE) %>% \n  factoextra::fviz_pca_biplot(geom.ind = \"point\",\n                              habillage = iris$Species,\n                              addEllipses = TRUE)\n\n\n\n\n\n\n Pra onde vai quem é o cliente\n\nEtapas de analise de resultados, validação, modelagem ou comunicação.\nInclusão em documento técnico reproduzível.\nComunicação de descobertas ou resultados de trabalhos técnicos\nDocumentação ou treinamento de pessoal.\n\n\n\n Qual o resultado\n\nAperfeiçoar as técnicas de representação, exploração e comunicação de estudos técnicos.\nFacilitar o entendimento das informações contidas nos documentos técnicos poupando tempo e dinheiro, permitindo a replicação e experimentos e consequentemente busca por melhoria.\nFacilitar o reconhecimento de registros, estudos, descobertas em pesquisas futuras."
  },
  {
    "objectID": "posts/confusion-matrix/index.html",
    "href": "posts/confusion-matrix/index.html",
    "title": "Avaliar resultados de modelo preditivo com matriz de confusão",
    "section": "",
    "text": "Vídeo tema para este post Avaliar resultados de modelo preditivo com matriz de confusão\n\n\n\n\n O que é uma matriz de confusão\n\nTabela que facilita a visualização das previsões corretas e as erradas em modelos de classificação.\nPossibilita a interpretação dos resultados sobre diversos pontos de vista desde que tenhamos os valores reais e os valores previstos pelo modelo.\n\n\n\nMatriz de confusão\n\n\n\nTP - verdadeiros positivos: Casos em que previmos que o paciênte tem a doença e ele realmente tem.\nTN - verdadeiro negativos: Casos em que previmos que o paciênte não tem a doença e ele realmente não tem.\nFP - falso positivo: Previmos que sim, mas na verdade ele não tem a doença. também conhecido como “erro do tipo 1”.\nFN - falso negativo: Previmos que não, mas na verdade ele tem a doença. também conhecido como “erro do tipo 2”.\n\n\n\n\n Qual o objetivo\n\nPor ser visual ajuda a responder rapidamente será que meu modelo teve um bom desempenho, onde deu errado, como posso corrigir ?\nAs diversas saídas de previõe permite a criação de indicadores que serão uteis nos ajustes mais adequados conforme a necessidade do trabalho que está sendo desenvolvido.\n\n\n\n De onde vem a demanda\n\nEm 1904 Karl Pearson criou a tabela de contingência. Por que precisamos e uma matriz de confusao se tevem a acuracidade ?\nImagine prever quantas pessoas estao infectadas com um virus contagioso antes de apresentar sintomas e isola-las da populacao saudavel.\n\n\n\n Como fazer\nPara reproduzir os códigos abaixo serão necessários os pacotes tidyverse , tidymodels e janitor\nO principal pacote que será usando para analisar uma matriz de confusão é o pacote yardstick que já é carregado quando chamamos o pacote tidymodels.\n\n#packages\nlibrary(tidyverse)\nlibrary(tidymodels)\n\n#check\ntwo_class_example %>% filter(Class1 >0.5) %>% janitor::tabyl(truth)\n\n  truth   n   percent\n Class1 227 0.8194946\n Class2  50 0.1805054\n\n#exemplo de tabela cruzada usando janitor\ntwo_class_example %>% \n  janitor::tabyl(truth, predicted) %>% \n  janitor::adorn_totals(where = c(\"col\", \"row\")) %>% \n  janitor::adorn_title()\n\n        predicted             \n  truth    Class1 Class2 Total\n Class1       227     31   258\n Class2        50    192   242\n  Total       277    223   500\n\n#trocando nomes\ntwo_class_example %>% \n  conf_mat(truth =truth, estimate =predicted, dnn =c(\"vlr_previsto\",\"vlr_real\"))\n\n            vlr_real\nvlr_previsto Class1 Class2\n      Class1    227     50\n      Class2     31    192\n\n#plot heatmap\ntwo_class_example %>% \n  conf_mat(truth = truth, estimate = predicted) %>% \n  autoplot(type = \"heatmap\")\n\n\n\n#acuracia- prop de acertos do modelo total de acerto / total previu\ntwo_class_example %>% \n  accuracy(truth= truth, estimate = predicted)\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.838\n\n#sensibilidade ou recall é a proporção de casos positivos classif corretamente\n#Raio X de aeroporto prioriza sensitivity\n#diagnóstico de cancer também pois o não diagnóstico resulta em atraso no tratamento\ntwo_class_example %>% \n  yardstick::sens(truth= truth, estimate = predicted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 sens    binary         0.880\n\n#Recall métrica útil nos casos em que o Falso Negativo supera o falso positivol\n#importante em casos médicos em que não importa se disparamos um alarme \n#falso, mas os casos positivos reais não devem passar despercebidos!\n#Em nosso exemplo, Recall seria uma métrica melhor porque não queremos dar alta \n#acidentalmente a uma pessoa infectada e deixá-la se misturar com a população \n#saudável,espalhando o vírus contagioso. \n#Agora você pode entender por que a acuracidade foi uma métrica ruim para modelo.\ntwo_class_example %>% \n  yardstick::recall(truth= truth, estimate = predicted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 recall  binary         0.880\n\n#kappa\ntwo_class_example %>% \n  yardstick::kap(truth= truth, estimate = predicted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 kap     binary         0.675\n\n#npv\ntwo_class_example %>% \n  yardstick::npv(truth= truth, estimate = predicted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 npv     binary         0.861\n\n#ppv\ntwo_class_example %>% \n  yardstick::ppv(truth= truth, estimate = predicted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 ppv     binary         0.819\n\n#A precisão é util nos casos em que os falsos positivos são uma preocupação \n#maior do que os falsos negativos.\n#A precisão é importante em sistemas de recomendação de música ou vídeo, \n#sites de comércio eletrônico, etc. Resultados errados podem levar à perda de \n#clientes e prejudicar o negócio.\ntwo_class_example %>% \n  yardstick::precision(truth= truth, estimate = predicted)\n\n# A tibble: 1 × 3\n  .metric   .estimator .estimate\n  <chr>     <chr>          <dbl>\n1 precision binary         0.819\n\n#spec\ntwo_class_example %>% \n  yardstick::spec(truth= truth, estimate = predicted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 spec    binary         0.793\n\n#roc_curve\ntwo_class_example %>% \n  roc_curve(truth = truth, estimate = Class1 ) %>% autoplot()\n\n\n\n#roc_auc\ntwo_class_example %>% \n  roc_auc(truth = truth, estimate = Class1 )\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.939\n\n\n\n\n\n\n\n\nDiferença entre incidência e prevalencia\n\n\n\n\n\nIncidencia é o número de casos recém-diagnosticados de uma doença. Número de novos casos de uma doença dividido pelo número de pessoas em risco para a doença. Se, ao longo de um ano, cinco mulheres são diagnosticadas com câncer de mama, de uma população total de 200 mulheres do estudo (que não têm câncer de mama no início do período de estudo), então diríamos que a incidência de câncer de mama câncer nesta população foi de 0,025. (ou 2.500 por 100.000 mulheres-anos de estudo)\nPrevalência é o número total de casos da doença existentes em uma população. A taxa de prevalência é o número total de casos de uma doença existente em uma população dividido pela população total. Assim, se uma medida de câncer é feita em uma população de 40.000 pessoas e 1.200 foram recentemente diagnosticadas com câncer e 3.500 estão vivendo com câncer, então a prevalência de câncer é de 0,118. (ou 11.750 por 100.000 pessoas)\nFonte: Departament of health - NY State at https://www.health.ny.gov/diseases/chronic/basicstat.htm\n\n\n\n\n\n Pra onde vai quem é o cliente\n\nA próxima etapa é o ajuste, finalização e comunicação do modelo.\n\n\n\n Qual o resultado\n\nAperfeiçoar as técnicas de avaliação de performance de modelos poupando tempo e dinheiro.\nFacilitar o processo de busca por melhorias nos modelos de previsão.\nMelhorar a comunicação dos resultados."
  },
  {
    "objectID": "posts/histogram/histogram.html",
    "href": "posts/histogram/histogram.html",
    "title": "Como analisar distribuição em dados - histograma curva normal",
    "section": "",
    "text": "O que é histograma\n\nGráfico que mostra como os dados coletados (amostra) estão distribuidos. Também mostra a média e como esses dados estão distante da média (desvio padrão e variância).\n\n\n\n\nHistograma\n\n\n\n\n Qual o objetivo\n\nObter uma resposta racional que auxilie na decisão (pre processamento, estudo do outlier, escolha do modelo mais adequado, identificação distorções na realidade).\n\n\n\n De onde vem a demanda\nDe questões como:\n\nComo está a distribuição de renda da população ?\nComo está a distribuição de peso na minha plantação de tomates?\nComo está a distribuição de altura das pessoas em determinada região?\nSerá que se eu separar em grupos eu consigo atender melhor as necessidades ?\n\n\n\n\n\n\n\nClique aqui pra abrir os detalhes\n\n\n\n\n\n . Imagine que eu queira prever o peso dos cachorros com base nas características deles.\n . Para explicar a distribuição dos pesos, tento dividir a população em grupos com base nessas características.\n . Em um agrupamento bem sucedido, os grupos terão baixa variação dentro do grupo e boa variação entre os grupos.\n . Na primeira tentativa, escolho jovem pelo curto, jovem pelo longo, velho pelo curto, jovem pelo longo.\n . Na segunda tentantiva escolho cães de trabalho atletico, trabalho faro, domestico atletico, domestico faro.\n . Na terceira tentativa escolho raças como pintcher, vira latas, pastor alemão e são bernardo.\n\n\n\n\n\n\nHistograma base para Anova\n\n\n\n\n Como fazer\nPara reproduzir os códigos abaixo serão necessários os pacotes tidyverse , rcompanion e janitor, ggpubr, funmodeling,skimr\n\nGráfico usando rcompanion\n\n# package -----------------------------------------------------------------\nlibrary(tidyverse)\nlibrary(rcompanion)\nlibrary(funModeling)\nlibrary(skimr)\nlibrary(ggpubr)\nlibrary(ggdist)\nlibrary(gghalves)\n\n# plot --------------------------------------------------------------------\n\n#rcompanion\nrcompanion::plotNormalHistogram(iris$Sepal.Length)\n\n\n\n\nGráfico usando funModeling\n\n#funmodeling\nmtcars %>% funModeling::plot_num()\n\n\n\n\nGráfico usando skimr\n\n#skimr\ndata(ames, package = \"modeldata\")\n\names %>% skimr::skim()\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n2930\n\n\nNumber of columns\n74\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n40\n\n\nnumeric\n34\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nMS_SubClass\n0\n1\nFALSE\n16\nOne: 1079, Two: 575, One: 287, One: 192\n\n\nMS_Zoning\n0\n1\nFALSE\n7\nRes: 2273, Res: 462, Flo: 139, Res: 27\n\n\nStreet\n0\n1\nFALSE\n2\nPav: 2918, Grv: 12\n\n\nAlley\n0\n1\nFALSE\n3\nNo_: 2732, Gra: 120, Pav: 78\n\n\nLot_Shape\n0\n1\nFALSE\n4\nReg: 1859, Sli: 979, Mod: 76, Irr: 16\n\n\nLand_Contour\n0\n1\nFALSE\n4\nLvl: 2633, HLS: 120, Bnk: 117, Low: 60\n\n\nUtilities\n0\n1\nFALSE\n3\nAll: 2927, NoS: 2, NoS: 1\n\n\nLot_Config\n0\n1\nFALSE\n5\nIns: 2140, Cor: 511, Cul: 180, FR2: 85\n\n\nLand_Slope\n0\n1\nFALSE\n3\nGtl: 2789, Mod: 125, Sev: 16\n\n\nNeighborhood\n0\n1\nFALSE\n28\nNor: 443, Col: 267, Old: 239, Edw: 194\n\n\nCondition_1\n0\n1\nFALSE\n9\nNor: 2522, Fee: 164, Art: 92, RRA: 50\n\n\nCondition_2\n0\n1\nFALSE\n8\nNor: 2900, Fee: 13, Art: 5, Pos: 4\n\n\nBldg_Type\n0\n1\nFALSE\n5\nOne: 2425, Twn: 233, Dup: 109, Twn: 101\n\n\nHouse_Style\n0\n1\nFALSE\n8\nOne: 1481, Two: 873, One: 314, SLv: 128\n\n\nOverall_Cond\n0\n1\nFALSE\n9\nAve: 1654, Abo: 533, Goo: 390, Ver: 144\n\n\nRoof_Style\n0\n1\nFALSE\n6\nGab: 2321, Hip: 551, Gam: 22, Fla: 20\n\n\nRoof_Matl\n0\n1\nFALSE\n8\nCom: 2887, Tar: 23, WdS: 9, WdS: 7\n\n\nExterior_1st\n0\n1\nFALSE\n16\nVin: 1026, Met: 450, HdB: 442, Wd : 420\n\n\nExterior_2nd\n0\n1\nFALSE\n17\nVin: 1015, Met: 447, HdB: 406, Wd : 397\n\n\nMas_Vnr_Type\n0\n1\nFALSE\n5\nNon: 1775, Brk: 880, Sto: 249, Brk: 25\n\n\nExter_Cond\n0\n1\nFALSE\n5\nTyp: 2549, Goo: 299, Fai: 67, Exc: 12\n\n\nFoundation\n0\n1\nFALSE\n6\nPCo: 1310, CBl: 1244, Brk: 311, Sla: 49\n\n\nBsmt_Cond\n0\n1\nFALSE\n6\nTyp: 2616, Goo: 122, Fai: 104, No_: 80\n\n\nBsmt_Exposure\n0\n1\nFALSE\n5\nNo: 1906, Av: 418, Gd: 284, Mn: 239\n\n\nBsmtFin_Type_1\n0\n1\nFALSE\n7\nGLQ: 859, Unf: 851, ALQ: 429, Rec: 288\n\n\nBsmtFin_Type_2\n0\n1\nFALSE\n7\nUnf: 2499, Rec: 106, LwQ: 89, No_: 81\n\n\nHeating\n0\n1\nFALSE\n6\nGas: 2885, Gas: 27, Gra: 9, Wal: 6\n\n\nHeating_QC\n0\n1\nFALSE\n5\nExc: 1495, Typ: 864, Goo: 476, Fai: 92\n\n\nCentral_Air\n0\n1\nFALSE\n2\nY: 2734, N: 196\n\n\nElectrical\n0\n1\nFALSE\n6\nSBr: 2682, Fus: 188, Fus: 50, Fus: 8\n\n\nFunctional\n0\n1\nFALSE\n8\nTyp: 2728, Min: 70, Min: 65, Mod: 35\n\n\nGarage_Type\n0\n1\nFALSE\n7\nAtt: 1731, Det: 782, Bui: 186, No_: 157\n\n\nGarage_Finish\n0\n1\nFALSE\n4\nUnf: 1231, RFn: 812, Fin: 728, No_: 159\n\n\nGarage_Cond\n0\n1\nFALSE\n6\nTyp: 2665, No_: 159, Fai: 74, Goo: 15\n\n\nPaved_Drive\n0\n1\nFALSE\n3\nPav: 2652, Dir: 216, Par: 62\n\n\nPool_QC\n0\n1\nFALSE\n5\nNo_: 2917, Exc: 4, Goo: 4, Typ: 3\n\n\nFence\n0\n1\nFALSE\n5\nNo_: 2358, Min: 330, Goo: 118, Goo: 112\n\n\nMisc_Feature\n0\n1\nFALSE\n6\nNon: 2824, She: 95, Gar: 5, Oth: 4\n\n\nSale_Type\n0\n1\nFALSE\n10\nWD : 2536, New: 239, COD: 87, Con: 26\n\n\nSale_Condition\n0\n1\nFALSE\n6\nNor: 2413, Par: 245, Abn: 190, Fam: 46\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nLot_Frontage\n0\n1\n57.65\n33.50\n0.00\n43.00\n63.00\n78.00\n313.00\n▇▇▁▁▁\n\n\nLot_Area\n0\n1\n10147.92\n7880.02\n1300.00\n7440.25\n9436.50\n11555.25\n215245.00\n▇▁▁▁▁\n\n\nYear_Built\n0\n1\n1971.36\n30.25\n1872.00\n1954.00\n1973.00\n2001.00\n2010.00\n▁▂▃▆▇\n\n\nYear_Remod_Add\n0\n1\n1984.27\n20.86\n1950.00\n1965.00\n1993.00\n2004.00\n2010.00\n▅▂▂▃▇\n\n\nMas_Vnr_Area\n0\n1\n101.10\n178.63\n0.00\n0.00\n0.00\n162.75\n1600.00\n▇▁▁▁▁\n\n\nBsmtFin_SF_1\n0\n1\n4.18\n2.23\n0.00\n3.00\n3.00\n7.00\n7.00\n▃▂▇▁▇\n\n\nBsmtFin_SF_2\n0\n1\n49.71\n169.14\n0.00\n0.00\n0.00\n0.00\n1526.00\n▇▁▁▁▁\n\n\nBsmt_Unf_SF\n0\n1\n559.07\n439.54\n0.00\n219.00\n465.50\n801.75\n2336.00\n▇▅▂▁▁\n\n\nTotal_Bsmt_SF\n0\n1\n1051.26\n440.97\n0.00\n793.00\n990.00\n1301.50\n6110.00\n▇▃▁▁▁\n\n\nFirst_Flr_SF\n0\n1\n1159.56\n391.89\n334.00\n876.25\n1084.00\n1384.00\n5095.00\n▇▃▁▁▁\n\n\nSecond_Flr_SF\n0\n1\n335.46\n428.40\n0.00\n0.00\n0.00\n703.75\n2065.00\n▇▃▂▁▁\n\n\nGr_Liv_Area\n0\n1\n1499.69\n505.51\n334.00\n1126.00\n1442.00\n1742.75\n5642.00\n▇▇▁▁▁\n\n\nBsmt_Full_Bath\n0\n1\n0.43\n0.52\n0.00\n0.00\n0.00\n1.00\n3.00\n▇▆▁▁▁\n\n\nBsmt_Half_Bath\n0\n1\n0.06\n0.25\n0.00\n0.00\n0.00\n0.00\n2.00\n▇▁▁▁▁\n\n\nFull_Bath\n0\n1\n1.57\n0.55\n0.00\n1.00\n2.00\n2.00\n4.00\n▁▇▇▁▁\n\n\nHalf_Bath\n0\n1\n0.38\n0.50\n0.00\n0.00\n0.00\n1.00\n2.00\n▇▁▅▁▁\n\n\nBedroom_AbvGr\n0\n1\n2.85\n0.83\n0.00\n2.00\n3.00\n3.00\n8.00\n▁▇▂▁▁\n\n\nKitchen_AbvGr\n0\n1\n1.04\n0.21\n0.00\n1.00\n1.00\n1.00\n3.00\n▁▇▁▁▁\n\n\nTotRms_AbvGrd\n0\n1\n6.44\n1.57\n2.00\n5.00\n6.00\n7.00\n15.00\n▁▇▂▁▁\n\n\nFireplaces\n0\n1\n0.60\n0.65\n0.00\n0.00\n1.00\n1.00\n4.00\n▇▇▁▁▁\n\n\nGarage_Cars\n0\n1\n1.77\n0.76\n0.00\n1.00\n2.00\n2.00\n5.00\n▅▇▂▁▁\n\n\nGarage_Area\n0\n1\n472.66\n215.19\n0.00\n320.00\n480.00\n576.00\n1488.00\n▃▇▃▁▁\n\n\nWood_Deck_SF\n0\n1\n93.75\n126.36\n0.00\n0.00\n0.00\n168.00\n1424.00\n▇▁▁▁▁\n\n\nOpen_Porch_SF\n0\n1\n47.53\n67.48\n0.00\n0.00\n27.00\n70.00\n742.00\n▇▁▁▁▁\n\n\nEnclosed_Porch\n0\n1\n23.01\n64.14\n0.00\n0.00\n0.00\n0.00\n1012.00\n▇▁▁▁▁\n\n\nThree_season_porch\n0\n1\n2.59\n25.14\n0.00\n0.00\n0.00\n0.00\n508.00\n▇▁▁▁▁\n\n\nScreen_Porch\n0\n1\n16.00\n56.09\n0.00\n0.00\n0.00\n0.00\n576.00\n▇▁▁▁▁\n\n\nPool_Area\n0\n1\n2.24\n35.60\n0.00\n0.00\n0.00\n0.00\n800.00\n▇▁▁▁▁\n\n\nMisc_Val\n0\n1\n50.64\n566.34\n0.00\n0.00\n0.00\n0.00\n17000.00\n▇▁▁▁▁\n\n\nMo_Sold\n0\n1\n6.22\n2.71\n1.00\n4.00\n6.00\n8.00\n12.00\n▅▆▇▃▃\n\n\nYear_Sold\n0\n1\n2007.79\n1.32\n2006.00\n2007.00\n2008.00\n2009.00\n2010.00\n▇▇▇▇▃\n\n\nSale_Price\n0\n1\n180796.06\n79886.69\n12789.00\n129500.00\n160000.00\n213500.00\n755000.00\n▇▇▁▁▁\n\n\nLongitude\n0\n1\n-93.64\n0.03\n-93.69\n-93.66\n-93.64\n-93.62\n-93.58\n▅▅▇▆▁\n\n\nLatitude\n0\n1\n42.03\n0.02\n41.99\n42.02\n42.03\n42.05\n42.06\n▂▂▇▇▇\n\n\n\n\n\nGráfico usando ggpubr\n\n#ggpubr\ndata(pistonrings, package = \"qcc\")\n\npistonrings %>% \n  ggpubr::gghistogram(x = \"diameter\", \n                      fill = \"trial\",\n                      add = \"mean\",\n                      rug = TRUE)\n\n\n\n\nGráfico usando base raincloud\n\n#raincloud\names <- ames %>% janitor::clean_names()\n\names %>% \n  mutate(sale_price = log10(sale_price)) %>% \n  ggplot(aes(x = heating_qc,\n             y = sale_price))+\n  ggdist::stat_halfeye()\n\n\n\n\n\n\n Pra onde vai quem é o cliente\n\nVai para a etapa de pre processamento ou ajuste de coleta de dados.\n\n\n\n Qual o resultado\n\nAperfeiçoar a avalição preliminar dos dados através da análise de distribuição.\nFacilitar o reconhecimento de determinados padrões que poderão influenciar nas decisões.\nMelhorar o entendimento sobre a natureza dos dados."
  },
  {
    "objectID": "posts/importar-visualizar/importar_visualizar.html",
    "href": "posts/importar-visualizar/importar_visualizar.html",
    "title": "Como importar e visualizar dados - Titanic dataset parte1",
    "section": "",
    "text": "O que é importação e visualização de dados\n\nÉ a etapa onde é feita extração de dados e avaliação se os mesmos podem contribuir para a solução do problema a ser resolvido.\nA visualização é uma forma intuitiva de traçar relações possíveis entre os dados e o desfecho permitindo a geração de questões e levantamento de hipóteses.\nGeralmente estão atrelados a uma métrica de sucesso e é feito após a etapa P do PDCA , PPDAC ou outro método de análise de fenõmeno e causa raíz utilizado.\n\n\n\nProcesso de projeto kaizen\n\n\n\n\n\n Qual o objetivo\n\nDisponibilizar recursos revelantes para solução dos problemas\nFiltrar dados relevantes dos não relevantes, entender a natureza dos dados se são realmente ruídos ou carecem de representação.\nAvaliar existencia de shadow stats ou se haverá dificuldade na coleta. Por exemplo: o dado pode ser muito relevante mas difícil de ser coletado ou pode haver muita instabilidade e ambiguidade ou até mesmo usar critérios diferentes entre diferentes fontes.\nGerar novas questões e hipóteses que poderão utilizar novos dados ou um resultado de interação entre os existentes.\n\n\n\n De onde vem a demanda\n\nA extração e visualização dos dados vem da necessidade de encontrar variáveis que expliquem o fenômeno e ajudem a prever eventos futuros.\nMelhorar e estimular a geração de ideias através da interação entre os envolvidos.\n\n\n\n Como fazer\nPara reproduzir os códigos abaixo serão necessários os pacotes tidyverse , tidymodels e janitor, ggpubr, funmodeling, ggalluvial e visdat\n\nO dados podem ser baixados no Kaggle titanic dataset\n\n# pacotes           --------------------------------------------------------\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(ggpubr)\nlibrary(funModeling)\nlibrary(ggalluvial)\nlibrary(visdat)\n\n# dados             --------------------------------------------------------\n#importar os dados do kaggle e salvar em  diretorio padrão\n\n# importar dados e padronizar colunas\ntrain_titanic <- \n    read.csv(\"train.csv\", na.strings = c(\"\",\" \")) %>% \n    clean_names() %>% \n    mutate(is_train = TRUE) \n\n#importar dados de teste\ntest_titanic <- \n  read.csv(\"test.csv\", na.strings = c(\"\",\" \")) %>% \n  clean_names() %>% \n  mutate(survived = NA, is_train = FALSE) \n\n#juntar os conjuntos\nsplit_titanic <- bind_rows(train_titanic, test_titanic)\n\n#check nas caracteristicas dos dados\nsplit_titanic %>% funModeling::df_status()\n\n       variable q_zeros p_zeros q_na  p_na q_inf p_inf      type unique\n1  passenger_id       0    0.00    0  0.00     0     0   integer   1309\n2      survived     549   41.94  418 31.93     0     0   integer      2\n3        pclass       0    0.00    0  0.00     0     0   integer      3\n4          name       0    0.00    0  0.00     0     0 character   1307\n5           sex       0    0.00    0  0.00     0     0 character      2\n6           age       0    0.00  263 20.09     0     0   numeric     98\n7        sib_sp     891   68.07    0  0.00     0     0   integer      7\n8         parch    1002   76.55    0  0.00     0     0   integer      8\n9        ticket       0    0.00    0  0.00     0     0 character    929\n10         fare      17    1.30    1  0.08     0     0   numeric    281\n11        cabin       0    0.00 1014 77.46     0     0 character    186\n12     embarked       0    0.00    2  0.15     0     0 character      3\n13     is_train     418   31.93    0  0.00     0     0   logical      2\n\n\nComo o nosso conjunto de dados é pequeno(tem poucas variáveis) é possível usar um gráfico para visualizar os tipos de dados e as características.\n\nsplit_titanic %>% visdat::vis_dat()\n\n\n\n\nGráfico Visdat - Características das variáveis\n\n\n\n\n\n\n\n\n\n\nComo faço pra visualizar dados faltantes quando o conjunto for grande ?\n\n\n\n\n\nSugestão É possível usar o pacote naniar com a função naniar::miss_var_summary()\n\n\n\nComo resultado da análise podemos verificar a necessidade de algumas transformações nos dados. Anotamos tudo para alterarmos posteriormente mas seguimos com a análise exploratória por enquanto.\n\nAlterar o tipo de variável de sex, embarked, survived, pclass = factor\nInserir dados faltantes em embarked = moda, age e fare = usando knn\n\nVamos fazer uma correlação para avaliar os padrões existentes. Mas note. Para fazer correlação, os dados precisam ser numéricos por isso usamos a função select_if(is.numeric) . Pelo padrão apresentado é possível verificar a existencia de dados categóricos eles geralmente ficam espaçados no gráfico e eles precisam ser transformados pra factor posteriormente e que já anotamos e comunicamos.\n\n# correlacao\ntrain_titanic %>% \n  select_if(is.numeric) %>% \n  GGally::ggscatmat(color = \"survived\", corMethod = \"spearman\")+\n  theme_pubclean()\n\n\n\n\nGráfico de correlação de Spearman\n\n\n\n\nSerá que a idade importa ?\n\n# age - será que a idade importa ? \ntrain_titanic %>% \n  ggplot(aes(x=age, fill = factor(survived)))+\n  geom_density(alpha =0.5)\n\n\n\n\n\n\n\n\nSerá que o sexo importa ?\n\n# age, sex and class - será que o sexo importa ?\ntrain_titanic %>% \n  ggplot(aes(x=pclass, fill= factor(survived)))+\n  geom_bar(stat = \"count\")+\n  facet_grid(~sex)\n\n\n\n\n\n\n\n\nVamos juntar as variáveis age+sex+pclass e analisar sob outro ponto de vista\n\n# age sex and class - sob outro ponto de vista\ntrain_titanic %>% \n  ggplot(aes(x=age, y=sex))+\n  geom_jitter(aes(color = factor(survived)))+\n  facet_wrap(~pclass)\n\n\n\n\n\n\n\n\nNovamente vamos analisar sob outro ponto de vista\n\n# sex, class e survived \ntrain_titanic %>% \n  group_by(sex, survived, pclass) %>% \n  summarise(qtd = n()) %>% \n  ggplot(aes(axis1=sex, axis2=pclass, axis3 = survived, y=qtd, fill= sex))+\n  geom_alluvium()+\n  geom_stratum()+\n  geom_text(stat = \"stratum\", aes(label = after_stat(stratum)))+\n  scale_x_discrete(limits = c(\"sex\", \"pclass\",\"survived\"))\n\n\n\n\n\n\n\n\nSerá que a variável tarifa está bem representada ?\n\n# fare - será que fare é uma variável válida ?\ntrain_titanic %>% \n  mutate(fare = fare) %>% \n  ggplot(aes(x=fare, y=pclass))+\n  geom_jitter(aes(color = factor(survived)))\n\n\n\n\n\n\n\n\nSera que o tamanho da familia importa e o dado está bem representado ?\n\n# parch sib_sp - será que o tamanho da familia importa ?\ntrain_titanic %>% \n  mutate(family_size = parch + sib_sp +1) %>%\n  ggboxplot(x=\"survived\", \n            y=\"family_size\", \n            fill= \"survived\",\n            palette = \"uchicago\")+\n  stat_compare_means()\n\n\n\n\n\n\n\n\nSerá que existe algum padrão no nome que possa ser extraído e que ajude a explicar se impacta na sobrevivência ?\n\n# title\ntrain_titanic %>% \n  mutate(title = str_extract(name, \"[A-z]*\\\\.\")) %>% \n  tabyl(title) %>% \n  adorn_pct_formatting() %>% \n  arrange(desc(n))\n\n     title   n percent\n       Mr. 517   58.0%\n     Miss. 182   20.4%\n      Mrs. 125   14.0%\n   Master.  40    4.5%\n       Dr.   7    0.8%\n      Rev.   6    0.7%\n      Col.   2    0.2%\n    Major.   2    0.2%\n     Mlle.   2    0.2%\n     Capt.   1    0.1%\n Countess.   1    0.1%\n      Don.   1    0.1%\n Jonkheer.   1    0.1%\n     Lady.   1    0.1%\n      Mme.   1    0.1%\n       Ms.   1    0.1%\n      Sir.   1    0.1%\n\n\n\n\n Pra onde vai quem é o cliente\n\nA próxima etapa é comunicar os resultados junto aos membros do projeto sobre as relações encontradas permitindo a interção e levantamento de novas necessidades ou hipóteses.\nPosteriormente, vem as etapas de pré processamento, modelo, validação e submissão.\n\n\n\n Qual o resultado\n\nAperfeiçoar a técnica de observação e representação de dados.\nFacilitar a comunicação com os envolvidos no projeto.\nMelhorar e estimular a geração de ideias através da interação entre os membros do projeto."
  },
  {
    "objectID": "posts/neural-net-nnet/neuralnet.html",
    "href": "posts/neural-net-nnet/neuralnet.html",
    "title": "Modelo preditivo usando com rede neural",
    "section": "",
    "text": "Vídeo tema para este post Redes neurais artificiais no R com nnet package\n\n\n\n\n O que é um modelo de rede neural\n\nRede neural é uma técnica que usa nós interconectados ou neuronios em uma estrutura de camadas com o objetivo de resolver problemas de previsão.\n\nRede neural regressãoRede neural Classificação\n\n\n\n\n\nRede Neural - Regressão\n\n\n\n\n\n\n\nRede Neural - Classificação\n\n\n\n\n\n\n\n\n Qual o objetivo\n\nA técnica é muito utilizada na solução de problemas de classificação onde o resultado(desfecho) é uma classe (e.g. gato, cachorro, cavalo).\nNeste exemplo, nós usaremos como exemplo uma linha de produção com sensores que registram características como largura e comprimento da pétala e sepala dos três tipos de flores iris: setosa, versicolor e virgínica.\nNosso objetivo é fazer um modelo de previsão o qual com base nessas características, consiga classificar cada tipo de flor e separá-las corretamente.\n\n\n\n De onde vem a demanda\n\nVem do uso de sistemas que utilizam visão computacional, processamento de linguagem natural em seu funcionamento como por exemplo veículos semi-autonomos, linhas de produção de veículos, controle de qualidade de autopeças entre outros.\nA primeira rede neural artificial foi implementada em 1958 por Frank Rosenblat e se chamava Perceptron e naquela época já se falava que era um embrião de um computador eletronico que seria capaz de andar, falar, ver, escrever e se reproduzir. Materia New York Times\n\n\n\n Como fazer\nNeste exemplo usaremos os pacotes tidyverse, janitor, tidymodels, nnet e neuralnettools\n\n# packages ----------------------------------------------------\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(nnet)\nlibrary(NeuralNetTools)\n\n# data --------------------------------------------------------\ndata_iris <- iris %>% janitor::clean_names()\n\nsplit_iris <- initial_split(data_iris, strata = species)\ntrain_iris <- training(split_iris)\ntest_iris  <- testing(split_iris)\n\n# model -------------------------------------------------------\nmdl_fit_nn_iris <- nnet(species ~., \n                        data = train_iris, \n                        size = 5, \n                        decay = 0.01, \n                        maxit = 500)\n\n# weights:  43\ninitial  value 142.466668 \niter  10 value 14.781617\niter  20 value 9.929478\niter  30 value 8.291768\niter  40 value 7.849535\niter  50 value 7.765939\niter  60 value 7.732812\niter  70 value 7.696247\niter  80 value 7.684596\niter  90 value 7.675855\niter 100 value 7.669159\niter 110 value 7.662754\niter 120 value 7.658608\niter 130 value 7.657329\niter 140 value 7.657058\niter 150 value 7.657015\nfinal  value 7.657012 \nconverged\n\n\nVamos fazer uma previsão usando o modelo que construímos e colocar o resultado dentro do dataframe com os dados de teste para podermos comparar valores previstos e realizados.\n\n# results -----------------------------------------------------\nmdl_fit_nn_iris %>% \n  predict(test_iris,type = \"class\") %>%\n  bind_cols(test_iris)\n\nNew names:\n• `` -> `...1`\n\n\n         ...1 sepal_length sepal_width petal_length petal_width    species\n1      setosa          4.9         3.0          1.4         0.2     setosa\n2      setosa          5.0         3.4          1.5         0.2     setosa\n3      setosa          5.4         3.7          1.5         0.2     setosa\n4      setosa          5.8         4.0          1.2         0.2     setosa\n5      setosa          5.1         3.5          1.4         0.3     setosa\n6      setosa          5.7         3.8          1.7         0.3     setosa\n7      setosa          5.4         3.4          1.7         0.2     setosa\n8      setosa          5.0         3.4          1.6         0.4     setosa\n9      setosa          4.9         3.6          1.4         0.1     setosa\n10     setosa          5.1         3.4          1.5         0.2     setosa\n11     setosa          5.0         3.5          1.6         0.6     setosa\n12     setosa          5.1         3.8          1.6         0.2     setosa\n13     setosa          5.3         3.7          1.5         0.2     setosa\n14 versicolor          5.5         2.3          4.0         1.3 versicolor\n15 versicolor          6.3         3.3          4.7         1.6 versicolor\n16 versicolor          4.9         2.4          3.3         1.0 versicolor\n17 versicolor          6.2         2.2          4.5         1.5 versicolor\n18 versicolor          5.6         2.5          3.9         1.1 versicolor\n19 versicolor          6.7         3.0          5.0         1.7 versicolor\n20 versicolor          5.7         2.6          3.5         1.0 versicolor\n21 versicolor          6.0         3.4          4.5         1.6 versicolor\n22 versicolor          6.7         3.1          4.7         1.5 versicolor\n23 versicolor          5.5         2.6          4.4         1.2 versicolor\n24 versicolor          5.6         2.7          4.2         1.3 versicolor\n25 versicolor          5.7         3.0          4.2         1.2 versicolor\n26 versicolor          5.7         2.8          4.1         1.3 versicolor\n27  virginica          7.1         3.0          5.9         2.1  virginica\n28  virginica          4.9         2.5          4.5         1.7  virginica\n29  virginica          5.7         2.5          5.0         2.0  virginica\n30  virginica          5.8         2.8          5.1         2.4  virginica\n31  virginica          6.4         3.2          5.3         2.3  virginica\n32  virginica          7.7         2.8          6.7         2.0  virginica\n33  virginica          6.2         2.8          4.8         1.8  virginica\n34  virginica          7.2         3.0          5.8         1.6  virginica\n35  virginica          7.9         3.8          6.4         2.0  virginica\n36 versicolor          6.1         2.6          5.6         1.4  virginica\n37  virginica          6.4         3.1          5.5         1.8  virginica\n38  virginica          5.8         2.7          5.1         1.9  virginica\n39  virginica          6.3         2.5          5.0         1.9  virginica\n\n\nComo já temos o resultados previstos e o real, podemos fazer uma matriz de confusão para facilitar a visualização dos resultados e analisar o desempenho inicial do modelo.\n\n#confusion matrix\ntable(test_iris$species,\n      predict(mdl_fit_nn_iris,\n              newdata = test_iris, \n              type = \"class\"))\n\n            \n             setosa versicolor virginica\n  setosa         13          0         0\n  versicolor      0         13         0\n  virginica       0          1        12\n\n\nComo ficou o resultado da previsão ?\n\n#predict classes\npredict(mdl_fit_nn_iris, test_iris, type = \"class\")\n\n [1] \"setosa\"     \"setosa\"     \"setosa\"     \"setosa\"     \"setosa\"    \n [6] \"setosa\"     \"setosa\"     \"setosa\"     \"setosa\"     \"setosa\"    \n[11] \"setosa\"     \"setosa\"     \"setosa\"     \"versicolor\" \"versicolor\"\n[16] \"versicolor\" \"versicolor\" \"versicolor\" \"versicolor\" \"versicolor\"\n[21] \"versicolor\" \"versicolor\" \"versicolor\" \"versicolor\" \"versicolor\"\n[26] \"versicolor\" \"virginica\"  \"virginica\"  \"virginica\"  \"virginica\" \n[31] \"virginica\"  \"virginica\"  \"virginica\"  \"virginica\"  \"virginica\" \n[36] \"versicolor\" \"virginica\"  \"virginica\"  \"virginica\" \n\n\nPlotando o modelo que acabamos de fazer\n\n#plotando o gráfico\nNeuralNetTools::plotnet(mdl_fit_nn_iris,pad_x=0.55, circle_col = \"grey90\")\n\n\n\n\n\n\n Pra onde vai quem é o cliente\n\nUm modelos de previsão de classificação pode ser embarcado dentro do sistema de produção.\nO modelo que fizemos é bastante simples e serve apenas como base para aprendizado, como próximo passo o uso de validação cruzada (cross validation) pode ser uma excelente opção para complementar o que aprendemos aqui.\n\n\n\n Qual o resultado\n\nAperfeiçoar as técnicas de contrução de modelos e solução de problemas de classificação para que estes possam auxiliar na produtividade da industria de flores que usamos como exemplo.\nFacilitar o processo de classificação.\nMelhorar o processo de produção, qualidade do produto, satisfação do consumidor e competitividade do negócio."
  },
  {
    "objectID": "posts/pattern-recognition/pattern_recognition.html",
    "href": "posts/pattern-recognition/pattern_recognition.html",
    "title": "Como Identificar padrões em dados - gráfico de dispersão",
    "section": "",
    "text": "O que são padrões em dados\n\nPadrões são fenômenos que se repetem de forma regular com base em alguma regra ou em condições definidas.\nPadrões nos permite fazer comparações e com isso deu origem a descobertas e invenções as quais são resultados da habilidade humanda de reconhecer padrões.\nReconhecer padrões requer repetição da experiência, e compreender os padrões é um dos fundamentos do pensamento matemático e resolução de problemas.\nExemplo de padrões - número, som, imagem, cores, plantas, linguagem.\n\n\n\n\nTabuleta de barro micenica de 1200 antes de Cristo com informações sobre a distrubição de couro bovino, suíno e veado aos sapateiros - PY Ub 1318\n\n\n\n\n Qual o objetivo\n\nPermitir que possamos fazer previsões e ou explicar melhor o fenômeno.\nEncontrar dados relevantes para que consigamos replicar esses fenomenos para construir coisas que melhorem e simplifiquem nossa vida\n\n\n\n De onde vem a demanda\n\nDa necessidade de investigar as características com visão ampla sobre diversos pontos de vista PDCA.\nNo exemplo utilizado a)Quem eram as vítimas ? b)Em que período ele as intoxicava ? c)Em qual período de tempo ?\n\n\n\n\nPDCA - Etapa 2\n\n\n\n\n Como fazer\nPara reproduzir os códigos abaixo serão necessários os pacotes tidyverse , ggExtra e janitor\n\nO dados podem ser baixados no github de David Spiegelhalter\n\n# packages  --------------------------------------------------------------------\n\nlibrary(tidyverse)\nlibrary(ggExtra)\nlibrary(janitor)\nlibrary(scales)\n\n# data  -------------------------------------------------------------------\ndata_crime <- \n  read.csv(\"https://raw.githubusercontent.com/dspiegel29/ArtofStatistics/master/00-1-age-and-year-of-deathofharold-shipmans-victims/00-1-shipman-confirmed-victims-x.csv\") %>% \n  janitor::clean_names()\n\ncrime_time <- \n  read.csv(\"https://raw.githubusercontent.com/dspiegel29/ArtofStatistics/master/00-2-shipman-times/00-2-shipman-times-x.csv\") %>% \n  janitor::clean_names()\n\n# plot    -------------------------------------------------------------------\n#diagrama de dispersao\nplot <- \ndata_crime %>% \n  ggplot(aes(x = fractional_death_year, y = age, color = gender2))+\n  geom_point()+\n  labs(title = \"vitimas de shipman\",\n       x = \"ano\",\n       y = \"idade\")+\n  theme(legend.title = element_blank(), legend.position = c(.125,1.15))\n\nggExtra::ggMarginal(plot, type = \"histogram\")\n\n\n\n\n\n\n\n#linha\ncrime_time %>% \n  ggplot(aes(x= hour, y))+\n  geom_line(aes(y = shipman, col = \"Shipman\"))+\n  geom_line(aes(y = comparison, col = \"Outros\"))+\n  scale_y_continuous(limits = c(0,15), labels = label_percent(scale=1))\n\n\n\n\n\n\n\n\n\n\n Pra onde vai quem é o cliente\n\nA próxima etapa pra quem usa o PDCA é a busca pelas causas fundamentais do problema.\n\n\n\n\nPDCA - Etapa 3\n\n\n\n\n Qual o resultado\n\nAperfeiçoar as técnicas de análise de fenômeno encurtando o tempo para explicação ou solução de algum problema\nFacilitar a replicação do fenômeno e consequentemente a comunicação.\nMelhorar as chances de sucesso na solução de problemas ou fazer qualquer coisa bem.\n\n\n\n Referência\n\n\n\nA arte da estatística: Como aprender a partir de dados por David Spiegelhalter, George Schlesinger"
  },
  {
    "objectID": "posts/table_stats/table_stats.html",
    "href": "posts/table_stats/table_stats.html",
    "title": "Como construir tabela para artigo técnico - gtsummary",
    "section": "",
    "text": "O que é uma tabela de dados\n\nTabela é um meio eficiente de representação e comunicação de dados tendo como características principais linhas, colunas, sumarizações e comparativos.\nDevido a versatilidade e capacidade de informações, é comum o uso em publicações técnicas e científicas.\n\n\n\n\n\n\n\n\n(a) Tabuleta de barro de 539 antes de Cristo de Nippur Mesopotâmia atual Iraque, considerada uma das primeiras planilhas\n\n\n\n\n\n\n\n(b) Resultado financeiro de uma empresa DRE\n\n\n\n\n\n\n\n(c) Modelo de tabela nutricional de lasanha congelada- FDA\n\n\n\n\nFigure 1: Exemplo de tabelas: Créditos para Penn Museum, factorialmap, FDA Food and Drug Administration\n\n\n\n\n Qual o objetivo\n\nRepresentar de forma compacta informações importantes que podem ser difíceis de expressar em texto ou gráficos.\nPermitir a comparação entre valores, resumir ou definir conceitos, termos ou outros detalhes de um estudo.\nPermitir que o leitor veja rapidamente os resultados de dados complexos os quais são organizados e descritos adequadamente no texto Slutsky (2014).\nTrazer clareza nos resultados apresentados.\n\n\n\n De onde vem a demanda\n\nDa necessidade de registrar, computar e comunicar dados.\nNecessidade de mostrar muitos valores em um pequeno espaço.\nNecessidade de comparar e contrastar valores de dados com várias características ou variáveis compartilhadas.\nPara mostrar a presença ou ausência de características específicas.\n\n\n\n Como fazer\nPara reproduzir os códigos abaixo serão necessários os pacotes tidyverse, janitor, gtsummary, gtExtras, gt.\nO dados usados iris, mtcars, trial, os quais estão nos pacotes que serão carregados não sendo necessário baixá-los. Já o dado corn pode ser baixado em Kniss AR, Streibig JC (2018) Statistical Analysis of Agricultural Experiments using R\n Entender bem a estrutura dos dados pode facilitar o trabalho de construção de tabelas .\n\n\n\n\nflowchart LR\n    A[Variável] -->B(Numerica)\n    A -->C(Categórica)\n    B --> D{Número \\n inteiro?}\n    D -->|Sim| E(Discreto)\n    D -->|Não| F(Contínuo)\n    C --> G{Quantas \\n categorias?}\n    G -->|Duas|H(Binária\\Dicotômica)\n    G -->|Três ou mais|I{Segue \\n uma ordem?}\n    I -->|Sim|J(Ordinal)\n    I -->|Não|L(Norminal)\n\n\n\n\n\n\n\n\n\n# package          -----------------------------------------------------------------\nlibrary(tidyverse)\nlibrary(gtsummary)\nlibrary(gtExtras)\nlibrary(gt)\nlibrary(survival)\n\n# data             --------------------------------------------------------------------\ndata_mtcars <- mtcars %>% janitor::clean_names()\ndata_iris   <- iris %>% janitor::clean_names()\ndata_trial  <- trial\ndata_corn   <- read.csv(\"http://rstats4ag.org/data/irrigcorn.csv\") %>% \n  janitor::clean_names()\n\n\ndata_mtcars %>% \n  select(mpg, cyl, wt, vs) %>% \n  tbl_summary(by= vs,\n              label = c(mpg ~ \"Milhas/galão\",\n                        cyl ~ \"Cilindros\",\n                        wt ~ \"Peso\")) %>% \n  modify_header(label = \"**Variáveis**\",\n                stat_1 = \"V {n}\",\n                stat_2 = \"S {n}\") %>% \n  modify_spanning_header(c(\"stat_1\",\"stat_2\") ~ \"**Type of Engine**\") %>% \n  modify_caption(\"**Figura1. Consumo de gasolina por tipo de motor**\") %>% \n  add_difference() %>% \n  bold_p(t = 0.05) %>% \n  bold_labels() %>% \n  modify_caption(\"<div style='text-align:left;\n                 font-weight: bold;\n                 color:grey'>Figura1. Consumo de gasolina por tipo de motor </div>\")\n\n\n\n\n\n  Figura1. Consumo de gasolina por tipo de motor \n\n  \n  \n    \n      Variáveis\n      \n        Type of Engine\n      \n      Difference2\n      95% CI2,3\n      p-value2\n    \n    \n      V 181\n      S 141\n    \n  \n  \n    Milhas/galão\n15.7 (14.8, 19.1)\n22.8 (21.4, 29.6)\n-7.9\n-11, -4.4\n<0.001\n    Cilindros\n\n\n2.8\n1.8, 3.8\n\n    4\n1 (5.6%)\n10 (71%)\n\n\n\n    6\n3 (17%)\n4 (29%)\n\n\n\n    8\n14 (78%)\n0 (0%)\n\n\n\n    Peso\n3.57 (3.24, 3.84)\n2.62 (2.00, 3.21)\n1.1\n0.49, 1.7\n<0.001\n  \n  \n  \n    \n      1 Median (IQR); n (%)\n    \n    \n      2 Welch Two Sample t-test; Standardized Mean Difference\n    \n    \n      3 CI = Confidence Interval\n    \n  \n\n\n\n\n\nlibrary(survival)\n\n\ntbl_fit_logreg_trial <- \n  glm(response~ trt + grade + age, data = data_trial, family = binomial(link=\"logit\")) %>% \n  tbl_regression(exponentiate= TRUE)\n\ntbl_fit_coxph_trial <- \ncoxph(Surv(ttdeath, death)~ trt + grade + age, data = data_trial) %>% \n  tbl_regression(exponentiate = TRUE)\n\ntbl_merge(tbls = list(tbl_fit_logreg_trial, tbl_fit_coxph_trial),\n          tab_spanner = c(\"**Log reg**\", \"**Coxph**\"))\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      \n        Log reg\n      \n      \n        Coxph\n      \n    \n    \n      OR1\n      95% CI1\n      p-value\n      HR1\n      95% CI1\n      p-value\n    \n  \n  \n    Chemotherapy Treatment\n\n\n\n\n\n\n    Drug A\n—\n—\n\n—\n—\n\n    Drug B\n1.13\n0.60, 2.13\n0.7\n1.30\n0.88, 1.92\n0.2\n    Grade\n\n\n\n\n\n\n    I\n—\n—\n\n—\n—\n\n    II\n0.85\n0.39, 1.85\n0.7\n1.21\n0.73, 1.99\n0.5\n    III\n1.01\n0.47, 2.15\n>0.9\n1.79\n1.12, 2.86\n0.014\n    Age\n1.02\n1.00, 1.04\n0.10\n1.01\n0.99, 1.02\n0.3\n  \n  \n  \n    \n      1 OR = Odds Ratio, CI = Confidence Interval, HR = Hazard Ratio\n    \n  \n\n\n\n\n\ndata_corn %>% \n  select(irrig, yield_tonha, yield_bu_a) %>% \n  tbl_summary(by = irrig,\n              label = list(yield_tonha ~ \"Tons/hec\",\n                           yield_bu_a ~ \"Bushel Acre\")) %>% \n  add_difference() %>% \n  modify_header(label = \"**Yield**\") %>% \n  modify_spanning_header(all_stat_cols() ~ \"**Irrigation type** {N} \")\n\n\n\n\n\n  \n  \n    \n      Yield\n      \n        Irrigation type 96\n      \n      Difference2\n      95% CI2,3\n      p-value2\n    \n    \n      Full, N = 481\n      Limited, N = 481\n    \n  \n  \n    Tons/hec\n11.42 (10.67, 12.08)\n10.14 (9.40, 11.41)\n1.1\n0.63, 1.6\n<0.001\n    Bushel Acre\n182 (170, 192)\n162 (150, 182)\n18\n10, 26\n<0.001\n  \n  \n  \n    \n      1 Median (IQR)\n    \n    \n      2 Welch Two Sample t-test\n    \n    \n      3 CI = Confidence Interval\n    \n  \n\n\n\n\n\nmtcars %>%\n  slice_sample(n=8) %>% \n  gt() %>% \n  gt_theme_guardian() %>% \n  data_color(columns = mpg:hp, colors = c(\"white\",\"red\")) %>% \n  gt_highlight_rows(rows = 2, font_weight = \"bold\")\n\n\n\n\n\n  \n  \n    \n      mpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n  \n  \n    16.4\n8\n275.8\n180\n3.07\n4.070\n17.40\n0\n0\n3\n3\n    32.4\n4\n78.7\n66\n4.08\n2.200\n19.47\n1\n1\n4\n1\n    22.8\n4\n140.8\n95\n3.92\n3.150\n22.90\n1\n0\n4\n2\n    19.2\n6\n167.6\n123\n3.92\n3.440\n18.30\n1\n0\n4\n4\n    33.9\n4\n71.1\n65\n4.22\n1.835\n19.90\n1\n1\n4\n1\n    17.8\n6\n167.6\n123\n3.92\n3.440\n18.90\n1\n0\n4\n4\n    22.8\n4\n108.0\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n    14.3\n8\n360.0\n245\n3.21\n3.570\n15.84\n0\n0\n3\n4\n  \n  \n  \n\n\n\nmtcars %>% \n  group_by(cyl) %>% \n  summarise(mpg_data  = list(mpg), .groups = \"drop\") %>% \n  gt() %>% \n  gt_plt_sparkline(mpg_data)\n\n\n\n\n\n  \n  \n    \n      cyl\n      mpg_data\n    \n  \n  \n    4\n          21.4\n    6\n          19.7\n    8\n          15.0\n  \n  \n  \n\n\n\nmtcars %>% \n  group_by(cyl) %>% \n  summarise(mpg_dat = list(mpg)) %>% \n  gt() %>% \n  gt_plt_dist(mpg_dat)\n\n\n\n\n\n  \n  \n    \n      cyl\n      mpg_dat\n    \n  \n  \n    4\n          \n    6\n          \n    8\n          \n  \n  \n  \n\n\n\n\n\n\n Pra onde vai quem é o cliente\n\nEtapas de analise de resultados, validação, remodelagem ou comunicação.\nInclusão em documento técnico reproduzível.\nComunicação de descobertas ou resultados de trabalhos técnicos.\nDocumentação ou treinamento de pessoal.\n\n\n\n Qual o resultado\n\nAperfeiçoar as técnicas de representação, calculo e comunicação de dados e estudos técnicos\nFacilitar o entendimento das informações contidas nos documentos técnicos poupando tempo e dinheiro, permitindo a replicação e experimentos e consequentemente busca por melhoria.\nFacilitar o reconhecimento de registros, estudos, descobertas em pesquisas futuras\n\n\n\n\n\n\n\n\n(a) Registro de entrega de alimentos em diferentes regiões como Delta do Nilo. A receita em vermelho, a despesa em preto.\n\n\n\n\n\n\n\n(b) Arquivo de Merer registro de atividade de 200 homens durante a construção da pirâmide de Gizé\n\n\n\n\nFigure 2: Papiros escritos em Hierático em 2550 antes de Cristo final do reinado de Khufu(Queops) e usados para registrar atividades durante a construção da pirâmide de Khufu. Créditos: Museu do Cairo, Egito.\n\n\n\n\n\n\n\nReferences\n\nSlutsky, David. 2014. “The Use of Tables.” Journal of Wrist Surgery 03 (04): 219–19. https://doi.org/10.1055/s-0034-1395165."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Motivação para o blog",
    "section": "",
    "text": "Vídeo tema para este post Transição demográfcias Brasil e Japão\n\n\n\n\n Por que este blog e o canal no YouTube ?\nEm 2040 o Brasil terá uma população mais urbana e mais madura. A necessidade de aumento de produtividade no país estará em rota de colisão com a demanda por mão de obra qualificada em países desenvolvidos que estarão com suas populações diminuindo.\nO objetivo do canal e do blog é tentar auxiliar na melhoria de processos para que estejamos mais preparados quando chegarmos em 2040.\n\n\n\n\n\n\n\n Como serão divididos os tópicos ?\n\n\n\n\n\n\nClique aqui pra abrir os detalhes\n\n\n\n\n\n . Demanda, definição do problema, objetivos e métricas de sucesso - Contém a origem e tipos de necessidade que é o que torna todo o restante do trabalho necessário.\n . Dados - Contém conceitos com o objetivo de estimular a observação, abstração e entendimento sobre o que são dados.\n . Ferramentas - Contém ferramentas como R(RStudio), Oracle SQL*plus, Oracle SNO, SPSS, Sphinx, Qlikview, PowerBI e excel.\n . Exploração - Contém visualização de dados, análise exploratória, tabelas, queries, planilhas de excel, folhas de verificação etc.\n . Modelos - Contém alguns tipos de modelos descritivos, preditivos, inferenciais, otimização entre outros.\n . Versionamento e Reprodutibilidade - Contém processos para desenvolvimento de documentos reproduzíveis usando versionamento github, git, criação de documentos quarto_pub e rmardown, criação de livros bookdown entre outros.\n . Comunicação - Contém abordagens sobre comunicação das estatísticas e relatórios técnicos.\n . Aplicação - Contém histórico de ações e aplicações dos projetos.\n\n\n\n\n\n\n\n\n\n\n Como será divido cada post ?\nEm 2001 para facilitar o entendimento dos profissionais da operação em industria eu escolhi um padrão que ao longo do tempo vem se mostrando eficiente e utilizarei aqui.\n - O que é : qual a ideia do que está sendo abordado ?\n - Qual o objetivo : por que isso está sendo ou foi desenvolvido ?\n - De onde vem : quais as necessidades ou origem dessa demanda ? A motivação ?\n - Como fazer : qual o procedimento, código, sequência ou fluxo ?\n - Pra onde vai : quem é o consumidor disso ? Qual a aplicação prática ?\n - Qual o resultado : descrição dos resultados previstos ou comprovados."
  },
  {
    "objectID": "posts/comm-stats/comm_stat.html",
    "href": "posts/comm-stats/comm_stat.html",
    "title": "Como comunicar dados em artigos técnicos no R - Quarto",
    "section": "",
    "text": "Vídeo tema para este post em Como comunicar dados em artigos técnicos no R - Quarto\n\n\n\n\n O que é comunicação de dados\n\nEm um contexto mais geral, seria o processo relativo a transação de dados e ou informações entre 2 ou mais agentes.\nEm um contexto mais específico que será tratado nesse post é a demonstração de resultado técnico ou experimento em documentos(e.g. dossiê, poster scientific, blog, livro etc)\nMuito mais do que um documento, são ideias.\n\n\n\n Qual o objetivo\n\nDar suporte para ação adequada/eficiente em situações específicas usando sinais que podem ser visuais como escrita, fórmulas, gráficos e código reproduzível.\nFacilitar a aplicação do conceito techinical writing , facilitar a compreenção e por consequencia a busca por melhorias.\n\n\n\n De onde vem a demanda\n\nNecessidade de compreenção, reprodução ou melhoria de um processo.\nEscasses de recursos vs necessidade de melhoria da produtividade global dos fatores.\nNecessidade de transparência, credibilidade e consistência.\n\n\n\n\n\n\n\n\nModelo de rodovidas interestaduais nos Estados Unidos iniciado em 1919 e finalizado 1995.\n\n\n\n\n\n\n\nModelo de suburbio 1947-1951 Levittown Long Island Estados Unidos, modelo que está sendo usado até 2022.\n\n\n\n\nFigura 1: Exemplo de ações implementadas através do uso de reprodutibilidade de experimentos e ideias.\n\n\n\n\n Como fazer\n\nFerramenta: Quarto, rmarkdown, jupyter notebook, word, excel.\n\n\n\n\n\n\n\n\nFigura 2: Processo de comunicação de dados técnicos\n\n\n\nConceito: Uso de elementos que facilitem processo de comunicação como equations, citations, cross-reference, footnotes, embedded code, code chunck, inline code.\nPara reproduzir os códigos abaixo serão necessários os pacotes tidyverse e quarto\nPara instalar o quarto pub clique no link acima e siga os procedimentos(next>next>next). Após a instalação a opção criar um novo documento quarto vai aparecer automaticamente no RStudio.\n\n\n\n\n\n\n\n\nPara criar um novo documento usando o quarto\n\n\n\n\n\n\n\n(a) Para escolher o formato que o documento será gerado. No caso de escolher PDF será necessário instalar o pacote tinytex (demora um pouco)\n\n\n\n\nFigura 3: Gerando novo documento usando quarto_pub\n\n\n\nCódigo descrito no vídeo aqui\n\n\n\n Pra onde vai quem é o cliente\n\nPublicação intranet\nGithub\nZenodo\nKaggle\nPaperswithcode\nNCBI - National Center for Biotecnology Information\nServiço Brasileiro de Respostas técnicas\nBlog/Books/Poster\n\n\n\n Qual o resultado\n\nMelhoria da articulação permitindo expor com mais clareza os detalhes técnicos e os benefícios a respeito da ideia proposta.\nReutilização da ideia original (ao invés de partir do zero) mas incrementando melhorias, reduzindo tempo de implementação e se livrando de obstaculos ao longo do caminho consequentemente poupando recursos o que remete a continuidade e consistência.\nIncremento de qualidade e acessibilidade ao conheicmento, bens ou serviços resultando da melhoria das padrão de vida pessoas."
  },
  {
    "objectID": "posts/decision-tree-rpart/dtrpart.html",
    "href": "posts/decision-tree-rpart/dtrpart.html",
    "title": "Modelo preditivo | tidymodels decision tree rpart diabetes",
    "section": "",
    "text": "Vídeo tema para este post em Tidymodels decision tree model diabetes - rpart\n\n\n\n\n O que é modelo de arvore de decisão\n\nDecision tree models são modelos árvore de decisão baseadas em instruções if-then/e se utilizando os dados preditores. @kuhn2013, chap 8\nExemplo: if temperatura_corporal >= 38 and dor_no_corpo = SIM then doente = SIM else doente = NAO\nO modelo que iremos usar é o rpart também conhecido por particionamento recursivo.\n\n\n\n Qual o objetivo\n\nPrever a probabilidade de um paciente ter diabetes com base em medidas de diagnóstico incluídas no conjunto de dados.\nTodos os pacientes são mulheres de no mínimo 21 anos de idade e descendencia de Indios Pima\nNos dados temos variáveis preditoras (independentes) e uma variável de resposta (dependente).\nVariáveis independentes incluem o número de gestações, massa(IMC), nível de insulina, idade, espessura da pele entre outras.\n\n\n\n De onde vem a demanda\n\nNecessidade de praticar a construção de modelos machine learning usando o framework tidymodels.\n\n\n\n Como fazer\nPacotes\nPara reproduzir os códigos abaixo serão necessários os pacotes tidyverse , tidymodels e janitor\nDados\nO conjunto de dados é o Pima Indians Diabetes Database disponível na Universidade da California Irvine Machine Learning Repository, no kaggle e também no pacote mlbench no R.\n\n\n\n\n\n\nClique aqui para mostrar dados complementares sobre Pima Indian Diabetes\n\n\n\n\n\n\nPima US são povos indígenas, e hoje vivem principalmente em três reservas no Arizona: A Reserva do Rio Gila, A Reserva do Rio Salgado, A Reserva Ak-Chin\nOs índios Pima do Arizona são estudados por mais de 30 anos e intrigam os pesquisadores porque sofrem de uma das taxas mais altas de diabetes do mundo.\nEntre os índios Pima mexicanos, 5,6% dos homens e 8,5% das mulheres tinham diabetes, enquanto nos índios Pima do US 34,2% dos homens e 40,8% das mulheres tinham a doença (P < 0,01) prevalências significativamente maior nos americanos.\nCerca de metade dos Pimas do Arizona com 40 anos ou mais tem diabetes de início adulto, uma condição na qual a insulina é produzida em quantidades insuficientes para atender às necessidades do corpo.\nEstão severamente acima do peso sendo os jovens estão acima da média nos EUA onde 1 a cada 4 são considerados obesos.\nOutro problema no grupo e insuficiência renal decorrente do diabetes sendo que 60% dos Pimas do Arizona desenvolvem doença renal relacionada ao diabetes contra 30% da população americana.\nExpectativa de vida dos Pima é muito menor do que a média nacional 72/M 78/F. Nos Pima 53/M e 63/F\n\n\n\n\nFluxo de trabalho\n\nCódigo reproduzível\n\n\n\nPackages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\n\n\n\n\nData\n\ndata(PimaIndiansDiabetes, package = \"mlbench\")\n\ndata_pima <- PimaIndiansDiabetes %>% janitor::clean_names()\n\ndata_pima %>% funModeling::df_status()\ndata_pima %>% funModeling::plot_num()\n\ndata_pima_clean <- \n  data_pima %>% \n  mutate(across(c(\"pregnant\":\"mass\"), ~ifelse(.x==0,NA,.x))) \n\n\n\n\n\nExplore\n\ndata_pima_clean %>% \n  select(glucose, insulin, mass, diabetes) %>% \n  GGally::ggpairs(aes(color = diabetes, alpha =0.3))\n\n\n\n\n\nSplit the data\n\nsplit_pima <- initial_split(data_pima_clean, strata = diabetes)\ntrain_pima <- training(split_pima)\ntest_pima <- testing(split_pima)\n\nresample_pima <- vfold_cv(train_pima, strata = diabetes, v=5)\n\n\n\n\n\nPre processing\n\nrec_pima <- \n  recipe(diabetes~., data = train_pima) %>% \n  step_impute_knn(all_predictors()) \n\n\n\n\n\nModel Specification\n\nmdl_spec_rpart_pima <- \n  decision_tree() %>% \n  set_engine(\"rpart\") %>% \n  set_mode(\"classification\") %>% \n  set_args(cost_complexity= tune(),\n           tree_depth = tune(),\n           min_n = tune())\n\n\n\n\n\nModel Workflow\n\nwkfl_rpart_pima <- \n  workflow() %>% \n  add_recipe(rec_pima) %>% \n  add_model(mdl_spec_rpart_pima)\n\n\n\n\n\nHyperparameter tune\n\n# grid spec      ---------------------------------------------------------------\ngrid_pima <- \n  grid_regular(cost_complexity(),\n               tree_depth(),\n               min_n(),\n               levels = 3)\n\n# tune grid      ---------------------------------------------------------------\ndoParallel::registerDoParallel()\n\nset.seed(123)\ntune_grid_rpart_pima <- \n  tune_grid(wkfl_rpart_pima,\n            resamples = resample_pima,\n            grid = grid_pima,\n            metrics = metric_set(roc_auc,accuracy),\n            control = control_grid(save_pred = TRUE))\n\nbest_grid_rpart_pima <- tune_grid_rpart_pima %>% select_best(metric= \"roc_auc\")\n\n#final wkfl\nfinal_wkfl_rpart_pima <- \n  finalize_workflow(wkfl_rpart_pima, best_grid_rpart_pima)\n\n\n\n\n\nModel Evaluating\n\nmdl_eval_rpart_pima <- \n  final_wkfl_rpart_pima %>% \n  last_fit(split_pima)\n\nmdl_eval_rpart_pima %>% \n  extract_fit_engine() %>% \n  rpart.plot::rpart.plot(cex = 0.6,\n                         type = 3,\n                         roundint = FALSE)\n\n\n\n\n\nModel Fit\n\nmdl_fit_rpart_pima <- \n  final_wkfl_rpart_pima %>% \n  fit(data_pima_clean)\n\n\n\n\n\nMake predictions\n\nnew_data_pima <- \n  tribble(~pregnant, ~glucose, ~pressure,~triceps,~insulin, ~mass, ~pedigree, ~age,\n          2,87,68,34,77,38,0.41,25)\n\npredict(mdl_fit_rpart_pima, new_data = new_data_pima)\n\n\n\n\n\nVariable Importance\n\nmdl_fit_rpart_pima %>% \n  extract_fit_engine() %>% \n  vip::vip()\n\n\n\n\n Pra onde vai quem é o cliente\n\nRepositório de documento criados para praticar o desenvolvimento de modelos de previsão usando tidymodels.\n\n\n\n Qual o resultado\n\nAperfeiçoamento das técnicas de construção de modelos usando tidymodels.\nCriação de modelo de previsão que pode ser melhorado e aproveitado projetos futuros.\nEstimular a geração de ideias, dúvidas e conhecimento acerca do problema e também na construção de modelos de previsão."
  },
  {
    "objectID": "posts/presentation_reveljs/presentation.html",
    "href": "posts/presentation_reveljs/presentation.html",
    "title": "Comunicar trabalhos técnicos em apresentações no R com Quarto",
    "section": "",
    "text": "Vídeo tema para este post em Comunicar trabalhos técnicos em apresentações no R com Quarto\n\n\n\n\n O que é este exercício \n\nComo fazer relatório técnico e científico usando ferramenta Quarto no formado de apresentações de slides em reveljs.\n\n\n\n Qual o objetivo\n\nFacilitar a publicação dos experimentos realizados pelo pesquisador ou melhorista de processos.\n\n\n\n De onde vem a demanda\n\nNecessidade de desenvolver pesquisas reprodusíveis.\nDirecionar os esforços mais para o conteúdo da pesquisa e menos para ferramentas de apresentação.\n\n\n\n Como fazer\nPacotes\nPara reproduzir os códigos abaixo serão necessários os pacotes tidyverse, sjplot, gt, gtExtras e [funModeling](gt{target=“_blank”}\nDados\nO conjunto de dados é o gapminder disponível no pacote gapminder , no R podendo ser acessado via código install.package(\"gapminder)\nTime line das ferramentas disponíveis ao longo do tempo\n\nCódigo reproduzível\nO YML file é o cabeçalho do documento onde colocamo o título entre outros detalhes do documento como por exemplo as configurações globais que serão reproduzidas nas demais partes do documento.\n\n\n\nyml\n\n---\ntitle: \"Minha pesquisa\"\nauthor: \"Marcelo Carvalho\"\nformat: \n  revealjs:\n    chalkboard: true\n    multiplex: true\neditor: visual\nexecute:\n  echo: true\n---\n\n\nO resumo geralmente consiste em textos e pequenos códigos inline\n\n\n\nresumo\n\n## Resumo - SLIDE1\n\n-   Apresentações são formas comums de comunicação de resultados de expementos\n\n-   Existem muitas ferramentas disponíveis\n\n-   Este exercício vai mostrar algumas `quarto` e `reveljs`\n\n## Objetivo - SLIDE2\n\n-   Facilitar a publicação de experimentos realizados por pesquisadores e melhoristas de processos\n\n## Pacotes - SLIDE3\n\n-   Neste trabalho foram usados os seguintes pacotes do R\n\n#Código inserido no code-chunk\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(janitor)\nlibrary(gapminder)\n\n#Resultado gerado\n#&gt; 1.  Facilita o manuseio de dados\n#&gt; 2.  Facilita a construção de modelos\n#&gt; 3.  Facilita a padronização dos nomes das variáveis\n#&gt; 4.  Concentra os dados que serão usados no exercício\n\n\nO corpo consiste em código reproduzível\n\n\n\ncorpo\n\n## Dados - SLIDE4\n-   A base de dados utilizada será a `Gapminder`\n-   Possui `r nrow(gapminder)` linhas e `r ncol(gapminder)` colunas.\n-   Os detalhes da estrutura são apresentados abaixo\n\n## gerar os detalhes da estrutura de dados\ngapminder %&gt;% glimpse()\n\n\n## Exploração - SLIDE5\ngapminder %&gt;% funModeling::df_status()\n\n\n## Método - SLIDE6\n\n$$\nY_i= \\beta_0 + \\beta_1 X_i + \\epsilon_i\n$$\n\n$Y_i$= Variável dependente\n\n$\\beta_0$= Constante ou Intercept\n\n$\\beta_1$= Coeficiente ou Slope\n\n$X_i$= Variável independente\n\n$\\epsilon_i$= Erro (desvio)\n\n\n## Modelo - SLIDE7\nmdl_gapminder &lt;- \n  gapminder %&gt;% \n  mutate(qty_year = year - 2007) %&gt;% \n  group_nest(country) %&gt;% \n  mutate(mdl = map(data, ~lm(lifeExp~qty_year, data = .x))) %&gt;% \n  mutate(result = map(mdl, broom::glance)) %&gt;% \n  select(country, result) %&gt;% \n  unnest(result)\n\n\n\n## Plotar modelo - SLIDE8\n#| output-location: slide\n#| code-line-numbers: \"2|4\"\nmdl_gapminder %&gt;% \n  ggplot(aes(x = r.squared, y = fct_reorder(country, r.squared)))+\n  geom_point()+\n  scale_y_discrete(guide = guide_axis(check.overlap = TRUE))+\n  labs(x = NULL, y = NULL)\n\n## Conclusão - SLIDE9\n-   `r mdl_gapminder %&gt;% filter(country == \"Brazil\") %&gt;% select(r.squared) %&gt;% \nmutate(r.squared = scales::percent(r.squared, accuracy = 0.1))` da \nvariação na expectativa de vida no Brasil é explicada pela variação do tempo.\n-   Consigo aprofundar nas pesquisas para compreender se há outros fatores que talvez possam explicar as correlações ?\n\n## Complemento1 - SLIDE10\n#| output-location: column\nlibrary(gt)\nlibrary(gtExtras)\n\ndata(FANG, \n     package = \"tidyquant\")\n\ndata_fang &lt;- FANG\n\ndata_fang %&gt;% group_by(symbol) %&gt;%  \n  summarise(price = list(adjusted)) %&gt;% \n  gt() %&gt;% \n  gt_plt_sparkline(\n    price,\n    same_limit = FALSE,\n    fig_dim = c(20,40),\n    type = \"ref_median\")\n\n## Complemento2 - SLIDE11\nlibrary(sjPlot)\n\nmdl_mtcars &lt;- lm(mpg~wt + cyl, data = mtcars)\nsjPlot::tab_model(mdl_mtcars)\n\n\n\n\n Pra onde vai quem é o cliente\n\nPesquisadores e profissionais que precisam comunicar suas pesquisas e experimentos.\nMelhoristas de processo que precisam de documentos reproduzíveis em seus projetos.\n\n\n\n Qual o resultado\n\nAperfeiçoar habilidades na comunicação dos resultados dos experimentos..\nFacilitar a comunicação entre pesquisadores. Tidyverse usa design for humans ( %&gt;% significa e então).\nMelhorar produtividade na manufatura e serviços através da replicação dessas ações e experimentos."
  }
]