{
  "hash": "03201b604c04cb0650a304dc871f193b",
  "result": {
    "markdown": "---\ntitle: \"Avaliar resultados de modelo preditivo com matriz de confusão\"\nauthor: \"Marcelo Carvalho dos Anjos\"\ndate: \"2022-08-03\"\ncategories: [Modelos]\nimage: \"confusion_matrix.png\"\n---\n\n\n::: {.callout-tip appearance=\"simple\"}\nVídeo tema para este post [Avaliar resultados de modelo preditivo com matriz de confusão](https://youtu.be/eqvmtYXh_C4){target=\"_blank\"}\n:::\n\n### {{< fa 1 >}} [**O que é uma matriz de confusão**]{style=\"color: #5AC8BE ;\"}\n\n-   Tabela que facilita a visualização das previsões corretas e as erradas em modelos de classificação.\n\n-   Possibilita a interpretação dos resultados sobre diversos pontos de vista desde que tenhamos os **valores reais e os valores previstos pelo modelo.**\n\n    ![Matriz de confusão](confusion_matrix.png){width=\"605\"}\n\n    -   **TP - verdadeiros positivos:** Casos em que previmos que o paciênte tem a doença e ele realmente tem.\n\n    -   **TN - verdadeiro negativos:** Casos em que previmos que o paciênte não tem a doença e ele realmente não tem.\n\n    -   **FP - falso positivo:** Previmos que sim, mas na verdade ele não tem a doença. também conhecido como \"erro do tipo 1\".\n\n    -   **FN - falso negativo:** Previmos que não, mas na verdade ele tem a doença. também conhecido como \"erro do tipo 2\".\n\n### {{< fa 2 >}} [**Qual o objetivo**]{style=\"color: #5AC8BE ;\"}\n\n-   Por ser visual ajuda a responder rapidamente será que meu modelo teve um bom desempenho, onde deu errado, como posso corrigir ?\n\n-   As diversas saídas de previõe permite a criação de indicadores que serão uteis nos ajustes mais adequados conforme a necessidade do trabalho que está sendo desenvolvido.\n\n### {{< fa 3 >}} [**De onde vem a demanda**]{style=\"color: #5AC8BE ;\"}\n\n-   Em 1904 Karl Pearson criou a tabela de contingência. Por que precisamos e uma matriz de confusao se tevem a acuracidade ?\n\n-   Imagine prever quantas pessoas estao infectadas com um virus contagioso antes de apresentar sintomas e isola-las da populacao saudavel.\n\n### {{< fa 4 >}} [**Como fazer**]{style=\"color: #5AC8BE ;\"}\n\nPara reproduzir os códigos abaixo serão necessários os pacotes [tidyverse](https://www.tidyverse.org/){target=\"_blank\"} , [tidymodels](https://www.tidymodels.org/){target=\"_blank\"} e [janitor](https://github.com/sfirke/janitor){target=\"_blank\"}\\\nO principal pacote que será usando para analisar uma matriz de confusão é o pacote [yardstick](https://yardstick.tidymodels.org/){target=\"_blank\"} que já é carregado quando chamamos o pacote **tidymodels**.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#packages\nlibrary(tidyverse)\nlibrary(tidymodels)\n\n#check\ntwo_class_example %>% filter(Class1 >0.5) %>% janitor::tabyl(truth)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  truth   n   percent\n Class1 227 0.8194946\n Class2  50 0.1805054\n```\n:::\n\n```{.r .cell-code}\n#exemplo de tabela cruzada usando janitor\ntwo_class_example %>% \n  janitor::tabyl(truth, predicted) %>% \n  janitor::adorn_totals(where = c(\"col\", \"row\")) %>% \n  janitor::adorn_title()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        predicted             \n  truth    Class1 Class2 Total\n Class1       227     31   258\n Class2        50    192   242\n  Total       277    223   500\n```\n:::\n\n```{.r .cell-code}\n#trocando nomes\ntwo_class_example %>% \n  conf_mat(truth =truth, estimate =predicted, dnn =c(\"vlr_previsto\",\"vlr_real\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            vlr_real\nvlr_previsto Class1 Class2\n      Class1    227     50\n      Class2     31    192\n```\n:::\n\n```{.r .cell-code}\n#plot heatmap\ntwo_class_example %>% \n  conf_mat(truth = truth, estimate = predicted) %>% \n  autoplot(type = \"heatmap\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#acuracia- prop de acertos do modelo total de acerto / total previu\ntwo_class_example %>% \n  accuracy(truth= truth, estimate = predicted)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.838\n```\n:::\n\n```{.r .cell-code}\n#sensibilidade ou recall é a proporção de casos positivos classif corretamente\n#Raio X de aeroporto prioriza sensitivity\n#diagnóstico de cancer também pois o não diagnóstico resulta em atraso no tratamento\ntwo_class_example %>% \n  yardstick::sens(truth= truth, estimate = predicted)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 sens    binary         0.880\n```\n:::\n\n```{.r .cell-code}\n#Recall métrica útil nos casos em que o Falso Negativo supera o falso positivol\n#importante em casos médicos em que não importa se disparamos um alarme \n#falso, mas os casos positivos reais não devem passar despercebidos!\n#Em nosso exemplo, Recall seria uma métrica melhor porque não queremos dar alta \n#acidentalmente a uma pessoa infectada e deixá-la se misturar com a população \n#saudável,espalhando o vírus contagioso. \n#Agora você pode entender por que a acuracidade foi uma métrica ruim para modelo.\ntwo_class_example %>% \n  yardstick::recall(truth= truth, estimate = predicted)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 recall  binary         0.880\n```\n:::\n\n```{.r .cell-code}\n#kappa\ntwo_class_example %>% \n  yardstick::kap(truth= truth, estimate = predicted)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 kap     binary         0.675\n```\n:::\n\n```{.r .cell-code}\n#npv\ntwo_class_example %>% \n  yardstick::npv(truth= truth, estimate = predicted)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 npv     binary         0.861\n```\n:::\n\n```{.r .cell-code}\n#ppv\ntwo_class_example %>% \n  yardstick::ppv(truth= truth, estimate = predicted)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 ppv     binary         0.819\n```\n:::\n\n```{.r .cell-code}\n#A precisão é util nos casos em que os falsos positivos são uma preocupação \n#maior do que os falsos negativos.\n#A precisão é importante em sistemas de recomendação de música ou vídeo, \n#sites de comércio eletrônico, etc. Resultados errados podem levar à perda de \n#clientes e prejudicar o negócio.\ntwo_class_example %>% \n  yardstick::precision(truth= truth, estimate = predicted)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric   .estimator .estimate\n  <chr>     <chr>          <dbl>\n1 precision binary         0.819\n```\n:::\n\n```{.r .cell-code}\n#spec\ntwo_class_example %>% \n  yardstick::spec(truth= truth, estimate = predicted)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 spec    binary         0.793\n```\n:::\n\n```{.r .cell-code}\n#roc_curve\ntwo_class_example %>% \n  roc_curve(truth = truth, estimate = Class1 ) %>% autoplot()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-1-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#roc_auc\ntwo_class_example %>% \n  roc_auc(truth = truth, estimate = Class1 )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.939\n```\n:::\n:::\n\n\n::: {.callout-tip collapse=\"true\"}\n## Diferença entre incidência e prevalencia\n\n**Incidencia** é o número de casos recém-diagnosticados de uma doença. Número de novos casos de uma doença dividido pelo número de pessoas em risco para a doença. Se, ao longo de um ano, cinco mulheres são diagnosticadas com câncer de mama, de uma população total de 200 mulheres do estudo (que não têm câncer de mama no início do período de estudo), então diríamos que a incidência de câncer de mama câncer nesta população foi de 0,025. (ou 2.500 por 100.000 mulheres-anos de estudo)\n\n**Prevalência** é o número total de casos da doença existentes em uma população. A taxa de prevalência é o número total de casos de uma doença existente em uma população dividido pela população total. Assim, se uma medida de câncer é feita em uma população de 40.000 pessoas e 1.200 foram recentemente diagnosticadas com câncer e 3.500 estão vivendo com câncer, então a prevalência de câncer é de 0,118. (ou 11.750 por 100.000 pessoas)\n\nFonte: Departament of health - NY State at https://www.health.ny.gov/diseases/chronic/basicstat.htm\n:::\n\n### {{< fa 5 >}} [**Pra onde vai quem é o cliente**]{style=\"color: #5AC8BE ;\"}\n\n-   A próxima etapa é o ajuste, finalização e comunicação do modelo.\n\n### {{< fa 6 >}} [**Qual o resultado**]{style=\"color: #5AC8BE ;\"}\n\n-   Aperfeiçoar as técnicas de avaliação de performance de modelos poupando tempo e dinheiro.\n\n-   Facilitar o processo de busca por melhorias nos modelos de previsão.\n\n-   Melhorar a comunicação dos resultados.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}